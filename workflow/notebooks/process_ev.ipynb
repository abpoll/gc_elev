{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ae3738-6ce1-4625-9777-cb42c218896b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:10.682614Z",
     "iopub.status.busy": "2023-10-20T22:00:10.682172Z",
     "iopub.status.idle": "2023-10-20T22:00:10.724588Z",
     "shell.execute_reply": "2023-10-20T22:00:10.723506Z",
     "shell.execute_reply.started": "2023-10-20T22:00:10.682567Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf7aaad-086f-40a9-92e4-374d1efb7495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:10.727777Z",
     "iopub.status.busy": "2023-10-20T22:00:10.727333Z",
     "iopub.status.idle": "2023-10-20T22:00:12.722671Z",
     "shell.execute_reply": "2023-10-20T22:00:12.721862Z",
     "shell.execute_reply.started": "2023-10-20T22:00:10.727733Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import shape\n",
    "import rasterio \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "from pyproj import CRS\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "from util.files import *\n",
    "from util.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae98b55-a0e0-4e75-b3f3-b9dcc294234c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:12.723577Z",
     "iopub.status.busy": "2023-10-20T22:00:12.723341Z",
     "iopub.status.idle": "2023-10-20T22:00:12.736891Z",
     "shell.execute_reply": "2023-10-20T22:00:12.736133Z",
     "shell.execute_reply.started": "2023-10-20T22:00:12.723560Z"
    }
   },
   "outputs": [],
   "source": [
    "# FIPS will be passed in as an argument, one day...\n",
    "FIPS = '34007'\n",
    "# STATE ABBR and NATION will be derived from FIPS, one day...\n",
    "STATEABBR = 'NJ'\n",
    "NATION = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec963f-fac9-4bb2-ac41-364fde7dbcb8",
   "metadata": {},
   "source": [
    "# Process - everything ends up at county level and clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879462d-4490-4f69-88bf-15efa5de8d78",
   "metadata": {},
   "source": [
    "## Process clip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462240d3-88c1-461a-bcbd-22f0585387f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:13.357822Z",
     "iopub.status.busy": "2023-10-20T22:00:13.357586Z",
     "iopub.status.idle": "2023-10-20T22:00:13.386346Z",
     "shell.execute_reply": "2023-10-20T22:00:13.385135Z",
     "shell.execute_reply.started": "2023-10-20T22:00:13.357799Z"
    }
   },
   "outputs": [],
   "source": [
    "# For our case study, we are going to focus on Gloucester City, NJ\n",
    "# Our config.yaml loads in a county indexed clip file\n",
    "# so that we can restrict all our data to the GC boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4108629a-beb2-44ba-94a2-634f69a44dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:13.795836Z",
     "iopub.status.busy": "2023-10-20T22:00:13.795345Z",
     "iopub.status.idle": "2023-10-20T22:00:13.829820Z",
     "shell.execute_reply": "2023-10-20T22:00:13.828661Z",
     "shell.execute_reply.started": "2023-10-20T22:00:13.795789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data we downloaded from the county's REST API server\n",
    "clip_filep = join(REF_DIR_R, FIPS, 'clip.json')\n",
    "with open(clip_filep) as f:\n",
    "    clip_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08a969c-fd99-4dae-ae15-041f5be159f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:14.307472Z",
     "iopub.status.busy": "2023-10-20T22:00:14.305803Z",
     "iopub.status.idle": "2023-10-20T22:00:15.504046Z",
     "shell.execute_reply": "2023-10-20T22:00:15.502806Z",
     "shell.execute_reply.started": "2023-10-20T22:00:14.307410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use pandas to get the data in a form that is easier\n",
    "# to turn into a geodataframe for clipping\n",
    "clip_df = pd.json_normalize(clip_data['features'])\n",
    "# We want to make a polygon out of the geometry coordinates\n",
    "# We can access that from the original json object\n",
    "clip_geo = [shape(i['geometry']) for i in clip_data['features']]\n",
    "# We can create a geodataframe of clip_df by adding clip_geo\n",
    "# as its geometry column\n",
    "clip_gdf = gpd.GeoDataFrame(clip_df,\n",
    "                            crs=CLIP_CRS,\n",
    "                            geometry=clip_geo)\n",
    "\n",
    "# We can clean up the gdf by removing the\n",
    "# type, id, geometry.type and geometry.coordinates columns\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "clip_gdf = clip_gdf.drop(columns=drop_col)\n",
    "\n",
    "# Write the file out to interim\n",
    "clip_out_filep = join(FI, 'ref', FIPS, 'clip.gpkg')\n",
    "prepare_saving(clip_out_filep)\n",
    "clip_gdf.to_file(clip_out_filep,\n",
    "                 driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb2e91-abce-44c5-8a49-14efa3cae4e4",
   "metadata": {},
   "source": [
    "## Process NSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30dc5b6-24f2-4552-a274-465aab776350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T20:11:01.336658Z",
     "iopub.status.busy": "2023-10-20T20:11:01.336524Z",
     "iopub.status.idle": "2023-10-20T20:11:01.374731Z",
     "shell.execute_reply": "2023-10-20T20:11:01.373440Z",
     "shell.execute_reply.started": "2023-10-20T20:11:01.336643Z"
    }
   },
   "outputs": [],
   "source": [
    "# The NSI comes with all the data necessary for performing a standard \n",
    "# flood risk assessment. It is still useful to process the raw data.\n",
    "# Here, we subset to residential properties with 1 to 2 stories\n",
    "# and save as a geodataframe. These are the types of residences we have\n",
    "# multiple depth-damage functions for and a literature base to draw \n",
    "# from to introduce uncertainty in these loss estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d179e9-26c9-4f13-88c8-c54d7c1188c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:17.500417Z",
     "iopub.status.busy": "2023-10-20T22:00:17.499889Z",
     "iopub.status.idle": "2023-10-20T22:00:18.107178Z",
     "shell.execute_reply": "2023-10-20T22:00:18.106014Z",
     "shell.execute_reply.started": "2023-10-20T22:00:17.500369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read NSI, reset index upon reading\n",
    "# TODO - this will be json...\n",
    "nsi_filep = join(EXP_DIR_R, FIPS, 'nsi.pqt')\n",
    "nsi_full = pd.read_parquet(nsi_filep).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b268cd77-1947-4d88-8e34-b6010345b208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:18.234753Z",
     "iopub.status.busy": "2023-10-20T22:00:18.234287Z",
     "iopub.status.idle": "2023-10-20T22:00:18.487750Z",
     "shell.execute_reply": "2023-10-20T22:00:18.486899Z",
     "shell.execute_reply.started": "2023-10-20T22:00:18.234707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to gdf\n",
    "# This is useful for some spatial joins we need to perform\n",
    "# Convert to geodataframe\n",
    "geometry = gpd.points_from_xy(nsi_full['properties.x'],\n",
    "                             nsi_full['properties.y'])\n",
    "# The NSI CRS is EPSG 4326\n",
    "nsi_gdf = gpd.GeoDataFrame(nsi_full, geometry=geometry,\n",
    "                           crs=NSI_CRS)\n",
    "\n",
    "# Drop the following columns\n",
    "drop_cols = ['type', 'geometry.type', 'geometry.coordinates']\n",
    "nsi_gdf = nsi_gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in nsi_gdf.columns]\n",
    "nsi_gdf.columns = col_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dacc2ed-62c5-481c-8b0c-9c2b173d8604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:19.962273Z",
     "iopub.status.busy": "2023-10-20T22:00:19.962043Z",
     "iopub.status.idle": "2023-10-20T22:00:20.149774Z",
     "shell.execute_reply": "2023-10-20T22:00:20.148930Z",
     "shell.execute_reply.started": "2023-10-20T22:00:19.962253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset to residential properties and update\n",
    "# RES 1 - single family\n",
    "# RES 2 - manufactured home\n",
    "# RES 3 - multifamily (but could fit into a depth-damage function\n",
    "# archetype depending on # stories)\n",
    "# We are going to use RES1 for this case-study\n",
    "# It is the only occtype with hazus and naccs\n",
    "# DDFs and has less ambiguous classification\n",
    "\n",
    "# occtype category for easier use in loss estimation steps\n",
    "\n",
    "# Get residential structures\n",
    "nsi_res = nsi_gdf.loc[nsi_gdf['occtype'].str[:4] == 'RES1']\n",
    "\n",
    "# For this case-study, don't use any building with more \n",
    "# than 2 stories\n",
    "res1_3s_ind = nsi_res['num_story'] > 2\n",
    "# Final residential dataframe\n",
    "res_f = nsi_res.loc[~res1_3s_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca1d9e1-e9f1-4c5b-b55a-6c80e1f18b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:00:37.798764Z",
     "iopub.status.busy": "2023-10-20T22:00:37.798528Z",
     "iopub.status.idle": "2023-10-20T22:00:38.018600Z",
     "shell.execute_reply": "2023-10-20T22:00:38.017631Z",
     "shell.execute_reply.started": "2023-10-20T22:00:37.798745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset to relevant columns\n",
    "cols = ['fd_id', 'occtype', 'found_type', 'cbfips',\n",
    "        'ftprntsrc', 'found_ht', 'val_struct',\n",
    "        'val_cont', 'source', 'firmzone', 'ground_elv_m',\n",
    "        'geometry']\n",
    "\n",
    "res_out = res_f.loc[:,cols]\n",
    "\n",
    "# Clip to our clip boundary\n",
    "# They are in the same CRS\n",
    "nsi_clip_out = gpd.clip(res_out, clip_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5fffede-d15f-4a04-8bc0-7865247078a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T22:02:02.695741Z",
     "iopub.status.busy": "2023-10-20T22:02:02.695549Z",
     "iopub.status.idle": "2023-10-20T22:02:06.572811Z",
     "shell.execute_reply": "2023-10-20T22:02:06.570999Z",
     "shell.execute_reply.started": "2023-10-20T22:02:02.695726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write out to interim/exposure/FIPS/\n",
    "# Single family homes -- sf\n",
    "EXP_OUT_FILEP = join(EXP_DIR_I, FIPS, 'nsi_sf.gpkg')\n",
    "prepare_saving(EXP_OUT_FILEP)\n",
    "nsi_clip_out.to_file(EXP_OUT_FILEP, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6fa61-56df-40a0-9c3f-219d09d52597",
   "metadata": {},
   "source": [
    "## Process Depth-Damage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4fbb6-23b2-49b0-a485-6bc268bc92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VULN_DIR_UZ/physical/US/haz_fl_dept.csv & naccs_ddfs.csv\n",
    "\n",
    "# I want to adapt the code in nsi_unc/workflows/notebooks/loss_ensemble\n",
    "# and write out the HAZUS & NACCS dicts (the params)\n",
    "# I want to modify it for every half foot, not rounding to the\n",
    "# full foot - that will probably bug people\n",
    "# I also want to update the process_data.ipynt code\n",
    "# For both of these, code can be greatly condensed -- with some\n",
    "# if statement -- to be cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77a02a-d329-479f-8355-93f0a34ded2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T17:55:19.418873Z",
     "iopub.status.busy": "2023-10-20T17:55:19.418001Z",
     "iopub.status.idle": "2023-10-20T17:55:21.014322Z",
     "shell.execute_reply": "2023-10-20T17:55:21.012336Z",
     "shell.execute_reply.started": "2023-10-20T17:55:19.418819Z"
    }
   },
   "source": [
    "## Process Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3455e12-484b-4413-938e-7b2cfe935231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob for shp files in REF_DIR_UZ - we need to get these all at\n",
    "# our county level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe02b8-4e96-4bbf-8048-bfb4b9fda231",
   "metadata": {},
   "source": [
    "# Process Social Vulnerability Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d22ef-3464-4c89-94ce-e357e6607a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to process these all at the county level\n",
    "# sovi is in VULN_DIR_UZ/social/{STATEABBR}/SoVI2010_{STATEABBR}/...\n",
    "# can glob for .shp (no .shp.xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e07e31-71f1-46f0-a6a6-6bf8f1c5fa3f",
   "metadata": {},
   "source": [
    "# Link - everything to structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2018d7-a6db-4a2d-a2df-a57581e1d2c9",
   "metadata": {},
   "source": [
    "## Link NSI with Flood Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f461bca-7b68-43d3-b4c7-dc7c54a8898a",
   "metadata": {},
   "source": [
    "## Link NSI with Reference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e1bc-8f47-49c3-9f68-89247784d83c",
   "metadata": {},
   "source": [
    "## Link NSI with Social Vulnerability Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891c8d6-8b60-460d-acda-82a09febfa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flrisk",
   "language": "python",
   "name": "flrisk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

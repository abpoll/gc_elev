{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8127ac76-50ac-4a49-b1a6-2ff4d124bca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:02:13.461712Z",
     "iopub.status.busy": "2023-10-22T19:02:13.460706Z",
     "iopub.status.idle": "2023-10-22T19:02:13.760942Z",
     "shell.execute_reply": "2023-10-22T19:02:13.759849Z",
     "shell.execute_reply.started": "2023-10-22T19:02:13.461661Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c50021-e313-4b5c-8978-c41bb4b28bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:02:13.772703Z",
     "iopub.status.busy": "2023-10-22T19:02:13.771732Z",
     "iopub.status.idle": "2023-10-22T19:02:43.405007Z",
     "shell.execute_reply": "2023-10-22T19:02:43.403692Z",
     "shell.execute_reply.started": "2023-10-22T19:02:13.772654Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "from pyproj import CRS\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "from util.files import *\n",
    "from util.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3535d05c-7fef-4b4e-ad55-6abb0d8b3feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:02:43.408277Z",
     "iopub.status.busy": "2023-10-22T19:02:43.407437Z",
     "iopub.status.idle": "2023-10-22T19:02:43.572530Z",
     "shell.execute_reply": "2023-10-22T19:02:43.571399Z",
     "shell.execute_reply.started": "2023-10-22T19:02:43.408224Z"
    }
   },
   "outputs": [],
   "source": [
    "# FIPS will be passed in as an argument, one day...\n",
    "FIPS = '34007'\n",
    "# STATE ABBR and NATION will be derived from FIPS, one day...\n",
    "STATEABBR = 'NJ'\n",
    "NATION = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c0670-eb81-43d2-b837-bb909b784d4e",
   "metadata": {},
   "source": [
    "# Link NSI with Depth Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8eabf98-c186-4c36-a7ab-ef7457ac7923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:03:07.162685Z",
     "iopub.status.busy": "2023-10-22T19:03:07.161478Z",
     "iopub.status.idle": "2023-10-22T19:03:12.597285Z",
     "shell.execute_reply": "2023-10-22T19:03:12.596553Z",
     "shell.execute_reply.started": "2023-10-22T19:03:07.162627Z"
    }
   },
   "outputs": [],
   "source": [
    "# I want to reproject other files to the hazard CRS because\n",
    "# this is the data we want to maintain spatial accuracy with the most\n",
    "# I might want to clip this to the GC clip boundary since it can\n",
    "# potentially speed up some code for doing \n",
    "# point in raster, etc. \n",
    "# For my first pass linking up, I also want to include\n",
    "# the 5th and 95th percentile grids and just use\n",
    "# a heuristic approach for estimating the standard deviation\n",
    "# for a normal distribution\n",
    "# Get this standard deviation parameter and then use the median\n",
    "# value as the mean \n",
    "# That's all we get from the link NSI with hazard step...\n",
    "# Then in the ensemble merge step, we sample from\n",
    "# the spatially varying distribution across all RPs\n",
    "\n",
    "# To start, let's reproject the NSI to the HAZ_CRS\n",
    "# Then prepare the coordinates for point in raster checks\n",
    "nsi = gpd.read_file(join(EXP_DIR_I, FIPS, 'nsi_sf.gpkg'))\n",
    "nsi_reproj = nsi.to_crs(HAZ_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1157ff6d-a80f-4b5d-b69c-21f3d5b76391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:03:37.273125Z",
     "iopub.status.busy": "2023-10-22T19:03:37.272616Z",
     "iopub.status.idle": "2023-10-22T19:03:58.902306Z",
     "shell.execute_reply": "2023-10-22T19:03:58.901065Z",
     "shell.execute_reply.started": "2023-10-22T19:03:37.273091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store NSI coordinates in list\n"
     ]
    }
   ],
   "source": [
    "# For each depth grid, we will sample from the grid\n",
    "# by way of a list of coordinates from the reprojected\n",
    "# nsi geodataframe (this is the fastest way I know to do it)\n",
    "coords = zip(nsi_reproj['geometry'].x, nsi_reproj['geometry'].y)\n",
    "coord_list = [(x, y) for x, y in coords]\n",
    "print('Store NSI coordinates in list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d30e70-f0f2-4ce9-b504-0d424e0a4499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T19:06:13.589782Z",
     "iopub.status.busy": "2023-10-22T19:06:13.588871Z",
     "iopub.status.idle": "2023-10-22T19:16:20.418935Z",
     "shell.execute_reply": "2023-10-22T19:16:20.418156Z",
     "shell.execute_reply.started": "2023-10-22T19:06:13.589730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 001 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 001 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 001 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 002 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 002 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 002 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 005 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 005 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 005 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 010 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 010 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 010 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 015 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 015 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 015 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 020 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 020 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 020 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 025 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 025 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 025 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 050 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 050 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 050 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 075 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 075 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 075 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 100 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 100 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 100 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 200 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 200 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 200 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 500 RP depth grid for Lower percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 500 RP depth grid for Mid percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n",
      "Read in 500 RP depth grid for Upper percentile\n",
      "Sampled depth from grid:\n",
      "Added depths to list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll store series of fd_id/depth pairs for each rp_pctile\n",
    "# in a list and concat this into a df after iterating\n",
    "depth_list = []\n",
    "\n",
    "# Dictionary to store the depth grids\n",
    "dg_dict = {}\n",
    "\n",
    "# Loop through RPs and the percentiles\n",
    "# Probably should rename directories accordingly\n",
    "# since there the boostrapped percentile\n",
    "# is useful information \n",
    "for rp, pctile in itertools.product(RET_PERS, HAZ_DIRS):\n",
    "    pct = pctile.split('_')[-1]\n",
    "    dg = read_dg(rp, pctile)\n",
    "    print('Read in ' + rp + ' RP depth grid for ' \n",
    "          + pct + ' percentile')\n",
    "\n",
    "    # Sample from the depth grid based on structure locations\n",
    "    # I did some ground truthing in qgis\n",
    "    # It appears that the sampled values align correctly\n",
    "    sampled_depths = [x[0] for x in dg.sample(coord_list)]\n",
    "    print('Sampled depths from grid')\n",
    "\n",
    "    # Store the series \n",
    "    depths = pd.Series(sampled_depths,\n",
    "                       index=nsi_reproj['fd_id'],\n",
    "                       name='_'.join([rp, pct]))\n",
    "    # Add the series to the list of series\n",
    "    depth_list.append(depths)\n",
    "    print('Added depths to list\\n')\n",
    "\n",
    "\n",
    "# Concat to dataframe\n",
    "depth_df = pd.concat(depth_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7804506c-2ad8-459d-9cbc-f0e0cf64cbae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T20:06:39.276554Z",
     "iopub.status.busy": "2023-10-22T20:06:39.275473Z",
     "iopub.status.idle": "2023-10-22T20:06:39.741157Z",
     "shell.execute_reply": "2023-10-22T20:06:39.740022Z",
     "shell.execute_reply.started": "2023-10-22T20:06:39.276505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace nodata values with 0\n",
    "depth_df[depth_df == dg.nodata] = 0\n",
    "\n",
    "# Retain only structures with sum flood exposure\n",
    "depth_df_f = depth_df[depth_df.sum(axis=1) > 0]\n",
    "\n",
    "# Multiply by MTR_TO_FT to convert to feet\n",
    "depth_df_f = depth_df_f*MTR_TO_FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c982853b-fa68-41b4-b201-3429c2b5da7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T20:08:13.047074Z",
     "iopub.status.busy": "2023-10-22T20:08:13.045800Z",
     "iopub.status.idle": "2023-10-22T20:08:14.464861Z",
     "shell.execute_reply": "2023-10-22T20:08:14.463856Z",
     "shell.execute_reply.started": "2023-10-22T20:08:13.047029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write out dataframe that links fd_id to depths\n",
    "# with columns corresponding to RETPER_PCTILE (i.e. 500_Mid)\n",
    "nsi_depths_out = join(EXP_DIR_I, FIPS, 'nsi_depths.pqt')\n",
    "# Round to nearest foot\n",
    "# Depth-damage functions don't have nearly the precision\n",
    "# to make use of inches differences\n",
    "depth_df_f.reset_index().to_parquet(nsi_depths_out.round())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flrisk",
   "language": "python",
   "name": "flrisk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3437bec-20a3-47a7-81c7-982313ea7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98978fcf-f72e-4a6e-87e6-4d7e2f100b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import glob\n",
    "from os.path import join\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio \n",
    "import rasterio.plot\n",
    "import rasterio.mask\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "import matplotlib.colors as mpc\n",
    "from matplotlib import colormaps, cm\n",
    "from matplotlib.collections import PatchCollection\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "from util.files import *\n",
    "from util.const import *\n",
    "from util.ddfs import *\n",
    "from util.figures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d906166-743e-47df-89b4-1700d74567ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIPS will be passed in as an argument, one day...\n",
    "FIPS = '34007'\n",
    "# STATE ABBR and NATION will be derived from FIPS, one day...\n",
    "STATEABBR = 'NJ'\n",
    "NATION = 'US'\n",
    "\n",
    "# I think it also could make sense to pass in scenario and\n",
    "# ddf type as arguments. For main results\n",
    "# we're using 'mid' and 'naccs' but for generating\n",
    "# our sensitivity analysis results we will need to pass\n",
    "# in the other scenarios and 'hazus'\n",
    "scenarios = ['Mid']\n",
    "ddf_types = ['naccs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd63f8-662b-44e7-b244-246aab80fb1e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32345773-b12d-44aa-932d-5cae71e49dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geospatial data\n",
    "clip_geo = gpd.read_file(join(REF_DIR_I, FIPS, \"clip.gpkg\"))\n",
    "tract_geo = gpd.read_file(join(REF_DIR_I, FIPS, \"tract.gpkg\"))\n",
    "bg_geo = gpd.read_file(join(REF_DIR_I, FIPS, \"bg.gpkg\"))\n",
    "nsi_geo = gpd.read_file(join(EXP_DIR_I, FIPS, \"nsi_sf.gpkg\"))\n",
    "\n",
    "# including vulnerability data\n",
    "lmi = gpd.read_file(join(VULN_DIR_I, 'social', FIPS, 'lmi.gpkg'))\n",
    "ovb = gpd.read_file(join(VULN_DIR_I, 'social', FIPS, 'ovb.gpkg'))\n",
    "cejst = gpd.read_file(join(VULN_DIR_I, 'social', FIPS, 'cejst.gpkg'))\n",
    "sovi = gpd.read_file(join(VULN_DIR_I, 'social', FIPS, 'sovi.gpkg'))\n",
    "# and the indicators dataframe to subset for maps\n",
    "c_ind = pd.read_parquet(join(VULN_DIR_I, 'social', FIPS, 'c_indicators.pqt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccf0b3-0897-43fb-a2e2-f663e3a4d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the figures, we need the following data\n",
    "\n",
    "# The objective evaluations for each policy\n",
    "obj_filep = join(FO, 'pol_obj_vals.pqt')\n",
    "objs = pd.read_parquet(obj_filep)\n",
    "\n",
    "# The houses that are elevated for each policy\n",
    "elev_ids_filep = join(FO, 'pol_elev_ids.json')\n",
    "with open(elev_ids_filep, 'r') as fp:\n",
    "    elev_ids = json.load(fp)\n",
    "\n",
    "# The ensemble w/ opt heightenings & associated values\n",
    "# We will do some plots based on the expected value of some\n",
    "# metrics across SOWs\n",
    "# Load the ensemble data, along with the optimal\n",
    "# elevation results\n",
    "ens_agg_dfs = {}\n",
    "\n",
    "for scen in scenarios:\n",
    "    ens_filep = join(FO, 'ensemble_' + scen + '.pqt')\n",
    "    ens_df = pd.read_parquet(ens_filep)\n",
    "    print('Load data: ' + scen)\n",
    "    \n",
    "    for ddf_type in ddf_types:\n",
    "        opt_elev_filename = 'ens_opt_elev_' + ddf_type + '_' + scen + '.pqt'\n",
    "        opt_elev_df = pd.read_parquet(join(EXP_DIR_I, FIPS, opt_elev_filename))\n",
    "        print('Load opt elev: ' + ddf_type)\n",
    "\n",
    "        # Merge on fd_id and sow_ind to get eal_avoid, elev_cost, and opt_elev\n",
    "        # into the ensemble\n",
    "        ens_df_m = ens_df.merge(opt_elev_df,\n",
    "                                on=['fd_id', 'sow_ind'],\n",
    "                                suffixes=['','_opt'])\n",
    "\n",
    "        # Get ens_agg for rel_eal, resid_rel_eal, & val_s metrics\n",
    "        eal_col = ddf_type + '_eal'\n",
    "        ens_df_m['rel_eal'] = ens_df_m[eal_col]/ens_df_m['val_s']\n",
    "        ens_df_m['npv_opt'] = ens_df_m['pv_avoid'] - ens_df_m['pv_cost']\n",
    "        ens_df_m['elev_ft'] = ens_df_m['opt_elev'].astype(int)\n",
    "        ens_agg = ens_df_m.groupby('fd_id')[['rel_eal',\n",
    "                                             'npv_opt',\n",
    "                                             'pv_resid',\n",
    "                                             'elev_invst',\n",
    "                                             'resid_rel_eal',\n",
    "                                             'elev_ft',\n",
    "                                             'val_s']].mean().reset_index()\n",
    "\n",
    "        # We need to merge ens_agg with nsi_geo \n",
    "        ens_agg_plot = nsi_geo.merge(ens_agg,\n",
    "                                     how='inner',\n",
    "                                     on='fd_id')\n",
    "\n",
    "        ens_agg_dfs[scen + '_' + ddf_type] = ens_agg_plot\n",
    "\n",
    "        print('Store gdf of aggregated values\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778eb4a-ea5f-43dc-b389-208f8def77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset sovi and lmi based on their threshholds\n",
    "sovi = sovi[sovi['sovi'] > .6]\n",
    "lmi = lmi[lmi['Lowmod_pct'] > .5]\n",
    "ovb = ovb[ovb['ovb_crit'] != 'Adjacent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06e291-5016-4575-bba2-030176cd45c4",
   "metadata": {},
   "source": [
    "# Main Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d169b-1754-4067-bcc8-4ba308c5cc45",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f58b35-7928-4333-8aa7-7dc628e2ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "comm_list = [sovi, cejst, ovb, lmi]\n",
    "\n",
    "# Colormaps for eal_base \n",
    "# Trying 'sunset' from Paul Tol\n",
    "# https://cran.r-project.org/web/packages/khroma/\n",
    "# vignettes/tol.html#diverging-data\n",
    "cmap_eal_l = ['#FEDA8B', '#FDB366',\n",
    "              '#F67E4B', '#DD3D2D', '#A50026']\n",
    "cmap_eal = mpc.LinearSegmentedColormap.from_list(\"\", cmap_eal_l)\n",
    "\n",
    "\n",
    "title_dict = {\n",
    "    'lmi': 'FHA Low-Moderate Income',\n",
    "    'sovi': 'CDC Socially Vulnerable' ,\n",
    "    'cejst': 'Justice40 Community',\n",
    "    'ovb': 'NJ Overburdened'\n",
    "}\n",
    "\n",
    "comm_names = ['sovi', 'cejst', 'ovb', 'lmi']\n",
    "\n",
    "# Helps to zoom in on places where at-risk homes are\n",
    "total_bounds = ens_agg_dfs['Mid_naccs'].geometry.total_bounds\n",
    "buffer = .001\n",
    "minx = total_bounds[0] - buffer\n",
    "maxx = total_bounds[2] + buffer\n",
    "miny = total_bounds[1] - buffer\n",
    "maxy = total_bounds[3] + buffer\n",
    "bounds = [minx, miny, maxx, maxy]\n",
    "\n",
    "for scen in scenarios:\n",
    "    for ddf_type in ddf_types:\n",
    "\n",
    "        save_filename = join(FIG_DIR, 'Figure2',\n",
    "                             scen + '_' + ddf_type + '.png')\n",
    "        prepare_saving(save_filename)\n",
    "        ens_plot = ens_agg_dfs[scen + '_' + ddf_type]\n",
    "        \n",
    "        plot_risk_disadv(ens_plot, comm_list, comm_names, title_dict,\n",
    "                         tract_geo, save_filename, risk_cmap=cmap_eal,\n",
    "                         bounds=bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36ad79-cc71-4447-9a4d-78b349c5d52f",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca16886-9f01-4376-9648-1faff74447b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "budget = 3e6\n",
    "\n",
    "sort_cols = ['npv_opt',\n",
    "             'sovi', \n",
    "             'avoid_rel_eal',\n",
    "             'lmi',\n",
    "             'rel_eal',\n",
    "             'cejst']\n",
    "\n",
    "title_dict = {\n",
    "    'lmi': 'Criterion: Majority of Benefits in\\nLow-Mod Income Block Groups',\n",
    "    'npv_opt': 'Criterion: Highest to Lowest\\nNet Benefit' ,\n",
    "    'sovi': 'Criterion: Majority of Benefits in\\nCDC Socially Vulnerable',\n",
    "    'rel_eal': 'Criterion: Highest to Lowest\\nInitial Risk Burden',\n",
    "    'cejst': 'Criterion: Majority of Benefits in\\nJustice40 Communities',\n",
    "    'avoid_rel_eal': 'Criterion: Highest to Lowest\\nReduction in Risk Burden'\n",
    "}\n",
    "\n",
    "for scen in scenarios:\n",
    "    for ddf_type in ddf_types:\n",
    "        scenario = scen + '_' + ddf_type\n",
    "        save_filename = join(FIG_DIR, 'Figure3',\n",
    "                             scen + '_' + ddf_type + '_budget_' +\n",
    "                             str(budget)[0] + 'e6_.png')\n",
    "        prepare_saving(save_filename)\n",
    "        ens_plot = ens_agg_dfs[scenario]\n",
    "        \n",
    "        plot_alloc(ens_plot, elev_ids, scenario, budget, sort_cols,\n",
    "                   title_dict, save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105c7ca-c27b-469f-9df6-3b504477d4e8",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab753725-ebd6-4e08-8ae0-6464e4486b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The costs of meeting objectives\n",
    "\n",
    "color_dict = {\n",
    "    'sovi': \"#33BBEE\",\n",
    "    'lmi': \"#0077BB\",\n",
    "    'cejst': \"#009988\",\n",
    "    'avoid_rel_eal': \"#EE3377\",\n",
    "    'rel_eal': \"#CC3311\",\n",
    "    'npv_opt': \"#EE7733\",\n",
    "}\n",
    "\n",
    "obj_names = ['Net Benefit ($M)',\n",
    "             'Residual Risk ($M)',\n",
    "             'Inequity in Investment',\n",
    "             'Inequity in Residual Risk']\n",
    "\n",
    "avoid_eq_col = 'avoid_eq1'\n",
    "\n",
    "obj_cols = ['npv_plot', 'pv_resid_plot', avoid_eq_col, 'resid_eq']\n",
    "\n",
    "min_obj_cols = ['resid_eq', 'pv_resid_plot', avoid_eq_col]\n",
    "\n",
    "# For plotting purposes, we're not comparing this rule\n",
    "# for allocation since it hasn't been used this way yet\n",
    "objs_plot = objs[objs['sort'] != 'ovb']\n",
    "\n",
    "for scen in scenarios:\n",
    "    for ddf_type in ddf_types:\n",
    "        scenario = scen + '_' + ddf_type\n",
    "        save_filename = join(FIG_DIR, 'Figure4',\n",
    "                             scen + '_' + ddf_type + '.png')\n",
    "        prepare_saving(save_filename)\n",
    "\n",
    "        plot_objcst(objs_plot, obj_cols, obj_names,\n",
    "                    scenario, color_dict, min_obj_cols,\n",
    "                    avoid_eq_col,\n",
    "                    save_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50534a10-2689-47e0-923f-448d8291ffe7",
   "metadata": {},
   "source": [
    "# Main Summary Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b8f69-993e-497b-bb2a-16ce841dcba5",
   "metadata": {},
   "source": [
    "## Elevation project budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327b02e-58f2-4478-8eed-ad8a08a8d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to get adjustments for previous elevation projects\n",
    "# Load in fema assistance/grants\n",
    "hma_proj_filep = join(FR, 'pol', 'fema_assistance',\n",
    "                      'HazardMitigationAssistanceProjects.csv')\n",
    "\n",
    "hma_proj = pd.read_csv(hma_proj_filep)\n",
    "\n",
    "# Subset from hma_proj.projecType.unique() for\n",
    "# elevation of private structures\n",
    "# The entries are a bit messy and more sophisticated\n",
    "# data preparation could get a better estimate of the budgets\n",
    "# This is a good enough first pass for getting an idea\n",
    "# of the distribution of budgets for these projects\n",
    "proj_types = ['202.1: Elevation of Private Structures - Riverine',\n",
    "              '202.2: Elevation of Private Structures - Coastal',\n",
    "              ]\n",
    "elev_proj = hma_proj[hma_proj['projectType'].isin(proj_types)]\n",
    "\n",
    "# add a year column\n",
    "# We'll use the dateApproved year for a best guess of \n",
    "# what year the cost estimates reflect\n",
    "elev_proj['year'] = pd.to_datetime(elev_proj['dateApproved']).dt.year\n",
    "\n",
    "# Today price = historic_price * (2022 index / historic_index) \n",
    "upper_infl_filep = join(ABS_DIR, 'resources',\n",
    "                        'construction_deflator_new_sfh.xls')\n",
    "\n",
    "# Read in the construction deflator for single family homes\n",
    "upper_infl_filep = join(ABS_DIR, 'resources',\n",
    "                        'construction_deflator_new_sfh.xls')\n",
    "upper_infl = pd.read_excel(upper_infl_filep, header=4)\n",
    "\n",
    "# We will groupby on year for the average Laspeyres (Fixed) index\n",
    "# Then we will create the historic/2022 index values\n",
    "upper_infl['year'] = upper_infl['Date'].dt.year\n",
    "# Can also limit to 1993, the min year in the elev_proj dataframe\n",
    "# We also are using 2022 dollars because we have the whole year of\n",
    "# data for that\n",
    "upper_infl_lim = upper_infl[(upper_infl['year'] >= elev_proj['year'].min()) &\n",
    "                            (upper_infl['year'] <= 2022)]\n",
    "upper_infl_gb = upper_infl_lim.groupby('year')['Laspeyres (Fixed)'].mean()\n",
    "# Reset index, rename, and get our defaltor for each year\n",
    "cost_deflate = upper_infl_gb.reset_index()\n",
    "cost_deflate.columns = ['year', 'laspeyres']\n",
    "base_index = cost_deflate.loc[cost_deflate['year'] == 2022,\n",
    "                              'laspeyres'].iloc[0]\n",
    "cost_deflate.loc[:,'deflator'] = base_index/cost_deflate.loc[:, 'laspeyres']\n",
    "\n",
    "# Use the cost_deflate df to get a dict of year to deflator values\n",
    "# Then deflate the project amount column in elev proj\n",
    "cost_d_map = dict(zip(cost_deflate['year'], cost_deflate['deflator']))\n",
    "elev_proj['defl'] = elev_proj['year'].map(cost_d_map)\n",
    "elev_proj['cost2022'] = elev_proj['projectAmount']*elev_proj['defl']\n",
    "\n",
    "pct75 = str((elev_proj['cost2022'].quantile(.75)/1e6).round(3))\n",
    "pct80 = str((elev_proj['cost2022'].quantile(.8)/1e6).round(3))\n",
    "pct90 = str((elev_proj['cost2022'].quantile(.9)/1e6).round(3))\n",
    "pct95 = str((elev_proj['cost2022'].quantile(.95)/1e6).round(3))\n",
    "\n",
    "print('75th%ile of HMA project costs: ' + pct75)\n",
    "print('80th%ile of HMA project costs: ' + pct80)\n",
    "print('90th%ile of HMA project costs: ' + pct90)\n",
    "print('95th%ile of HMA project costs: ' + pct95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ba18c-5751-4443-a503-440595d56e74",
   "metadata": {},
   "source": [
    "## Cost effectiveness summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce148c4-ee82-45fa-bf39-85bfcdc2d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cost difference for same level of inequity in residual risk\n",
    "# with risk burden vs. other criteria\n",
    "# First, level w/ risk burden sorting at lowest cost\n",
    "low_resid_eq = objs[(objs['sort'].isin(['rel_eal', 'avoid_rel_eal'])) &\n",
    "                    (objs['budget'] == 1e6)]['resid_eq'].iloc[0]\n",
    "low_cost_resid_eq = objs[(objs['sort'].isin(['rel_eal', 'avoid_rel_eal'])) &\n",
    "                         (objs['budget'] == 1e6)]['up_cost'].iloc[0]\n",
    "\n",
    "# Commensurate cost of other policies at this level\n",
    "# Can use npv_opt sorting as the reference since\n",
    "# they all have the same costs & objective values at this point\n",
    "same_resid_eq_min_cost = objs[(objs['sort'].isin(['npv_opt'])) &\n",
    "                              (objs['resid_eq'] <= low_resid_eq)]['up_cost'].min()\n",
    "\n",
    "print('Risk burden sorting')\n",
    "print('Objective value at $1M budget: ' + str(np.round(low_resid_eq, 3)))\n",
    "print('Cost at $1M budget: ' + str(np.round(low_cost_resid_eq, 3)))\n",
    "print('\\nOther rules')\n",
    "print('Lowest cost policy with same objective value: ' +\n",
    "      str(np.round(same_resid_eq_min_cost, 3)))\n",
    "print('Ratio of costs: ' + str(np.round(same_resid_eq_min_cost/low_cost_resid_eq)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flrisk",
   "language": "python",
   "name": "flrisk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

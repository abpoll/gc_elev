{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e622f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:48:18.602900Z",
     "start_time": "2023-04-11T19:48:18.516130Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36099285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T20:21:49.033392Z",
     "start_time": "2023-04-11T20:21:48.281935Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import math\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fd02bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:48:23.284314Z",
     "start_time": "2023-04-11T19:48:23.254658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "\n",
    "# Get the absolute path to the precal_hazard directory\n",
    "# Which is two directories above notebooks/exploration/\n",
    "abs_dir = os.path.abspath(Path(os.getcwd()).parents[1])\n",
    "# Get raw data directory\n",
    "fr = join(abs_dir, 'data', 'raw')\n",
    "# Get interim data directory\n",
    "fi = join(abs_dir, 'data', 'interim')\n",
    "# Get processed data directory\n",
    "fp = join(abs_dir, 'data', 'processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97219c6c",
   "metadata": {},
   "source": [
    "# Get National Structure Inventory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b709c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:48:39.287228Z",
     "start_time": "2023-04-11T19:48:24.973083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the NSI API by fips\n",
    "# Camden, County NJ\n",
    "fips_list = ['34007']\n",
    "\n",
    "# Get the URL\n",
    "url = \"https://nsi.sec.usace.army.mil/nsiapi/structures\"\n",
    "\n",
    "# Loop through counties, \n",
    "# Get the data from the NSI API\n",
    "# Store in dataframe\n",
    "# Add to list\n",
    "# Concat all the dfs\n",
    "\n",
    "# List for NSI DFs\n",
    "nsi_df_list = []\n",
    "\n",
    "for fips in fips_list:\n",
    "    # GET Request\n",
    "    nsi_get = requests.get(url + '?fips=' + fips)\n",
    "    \n",
    "    # Temp data frame\n",
    "    temp = pd.json_normalize(nsi_get.json()['features'])\n",
    "    \n",
    "    # Add to list\n",
    "    nsi_df_list.append(temp)\n",
    "\n",
    "# Concat\n",
    "nsi = pd.concat(nsi_df_list, axis=0)\n",
    "\n",
    "# Write to file\n",
    "nsi.to_parquet(join(fr, 'exposure', 'nsi.pqt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e6de50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:54:19.738557Z",
     "start_time": "2023-04-11T19:54:19.373730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>geometry.type</th>\n",
       "      <th>geometry.coordinates</th>\n",
       "      <th>properties.fd_id</th>\n",
       "      <th>properties.bid</th>\n",
       "      <th>properties.occtype</th>\n",
       "      <th>properties.st_damcat</th>\n",
       "      <th>properties.bldgtype</th>\n",
       "      <th>properties.found_type</th>\n",
       "      <th>properties.cbfips</th>\n",
       "      <th>...</th>\n",
       "      <th>properties.val_vehic</th>\n",
       "      <th>properties.source</th>\n",
       "      <th>properties.med_yr_blt</th>\n",
       "      <th>properties.firmzone</th>\n",
       "      <th>properties.o65disable</th>\n",
       "      <th>properties.u65disable</th>\n",
       "      <th>properties.x</th>\n",
       "      <th>properties.y</th>\n",
       "      <th>properties.ground_elv</th>\n",
       "      <th>properties.ground_elv_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-75.027694, 39.836728]</td>\n",
       "      <td>549377745</td>\n",
       "      <td>87F6RXPC+MWV-7-10-8-9</td>\n",
       "      <td>COM3</td>\n",
       "      <td>COM</td>\n",
       "      <td>W</td>\n",
       "      <td>S</td>\n",
       "      <td>340076074012026</td>\n",
       "      <td>...</td>\n",
       "      <td>180000</td>\n",
       "      <td>X</td>\n",
       "      <td>1964</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-75.027694</td>\n",
       "      <td>39.836728</td>\n",
       "      <td>79.250601</td>\n",
       "      <td>24.155582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-75.028788, 39.939514]</td>\n",
       "      <td>549416164</td>\n",
       "      <td>87F6WXQC+RF4-12-13-12-14</td>\n",
       "      <td>COM3</td>\n",
       "      <td>COM</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>340076032003015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>1987</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-75.028788</td>\n",
       "      <td>39.939514</td>\n",
       "      <td>47.315855</td>\n",
       "      <td>14.421872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-75.033884, 39.91555]</td>\n",
       "      <td>549971600</td>\n",
       "      <td>87F6WX88+6C9-3-3-2-3</td>\n",
       "      <td>RES3A</td>\n",
       "      <td>RES</td>\n",
       "      <td>W</td>\n",
       "      <td>B</td>\n",
       "      <td>340076062001005</td>\n",
       "      <td>...</td>\n",
       "      <td>54000</td>\n",
       "      <td>X</td>\n",
       "      <td>1939</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-75.033884</td>\n",
       "      <td>39.915550</td>\n",
       "      <td>15.376165</td>\n",
       "      <td>4.686655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-75.084571, 39.955341]</td>\n",
       "      <td>550301356</td>\n",
       "      <td>87F6XW48+45M-4-4-4-4</td>\n",
       "      <td>RES1-2SWB</td>\n",
       "      <td>RES</td>\n",
       "      <td>W</td>\n",
       "      <td>B</td>\n",
       "      <td>340076011021001</td>\n",
       "      <td>...</td>\n",
       "      <td>27000</td>\n",
       "      <td>X</td>\n",
       "      <td>2003</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-75.084571</td>\n",
       "      <td>39.955341</td>\n",
       "      <td>18.458536</td>\n",
       "      <td>5.626162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-74.999513, 39.870824]</td>\n",
       "      <td>550414706</td>\n",
       "      <td>87F7V2C2+85H-3-3-3-3</td>\n",
       "      <td>COM8</td>\n",
       "      <td>COM</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>340076035051009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>1964</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-74.999513</td>\n",
       "      <td>39.870824</td>\n",
       "      <td>52.017050</td>\n",
       "      <td>15.854796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type geometry.type     geometry.coordinates  properties.fd_id  \\\n",
       "0  Feature         Point  [-75.027694, 39.836728]         549377745   \n",
       "1  Feature         Point  [-75.028788, 39.939514]         549416164   \n",
       "2  Feature         Point   [-75.033884, 39.91555]         549971600   \n",
       "3  Feature         Point  [-75.084571, 39.955341]         550301356   \n",
       "4  Feature         Point  [-74.999513, 39.870824]         550414706   \n",
       "\n",
       "             properties.bid properties.occtype properties.st_damcat  \\\n",
       "0     87F6RXPC+MWV-7-10-8-9               COM3                  COM   \n",
       "1  87F6WXQC+RF4-12-13-12-14               COM3                  COM   \n",
       "2      87F6WX88+6C9-3-3-2-3              RES3A                  RES   \n",
       "3      87F6XW48+45M-4-4-4-4          RES1-2SWB                  RES   \n",
       "4      87F7V2C2+85H-3-3-3-3               COM8                  COM   \n",
       "\n",
       "  properties.bldgtype properties.found_type properties.cbfips  ...  \\\n",
       "0                   W                     S   340076074012026  ...   \n",
       "1                   S                     S   340076032003015  ...   \n",
       "2                   W                     B   340076062001005  ...   \n",
       "3                   W                     B   340076011021001  ...   \n",
       "4                   M                     S   340076035051009  ...   \n",
       "\n",
       "   properties.val_vehic  properties.source  properties.med_yr_blt  \\\n",
       "0                180000                  X                   1964   \n",
       "1                     0                  X                   1987   \n",
       "2                 54000                  X                   1939   \n",
       "3                 27000                  X                   2003   \n",
       "4                     0                  X                   1964   \n",
       "\n",
       "   properties.firmzone  properties.o65disable  properties.u65disable  \\\n",
       "0                 None                   0.25                   0.04   \n",
       "1                 None                   0.25                   0.04   \n",
       "2                 None                   0.25                   0.04   \n",
       "3                 None                   0.25                   0.04   \n",
       "4                 None                   0.25                   0.04   \n",
       "\n",
       "  properties.x properties.y  properties.ground_elv  properties.ground_elv_m  \n",
       "0   -75.027694    39.836728              79.250601                24.155582  \n",
       "1   -75.028788    39.939514              47.315855                14.421872  \n",
       "2   -75.033884    39.915550              15.376165                 4.686655  \n",
       "3   -75.084571    39.955341              18.458536                 5.626162  \n",
       "4   -74.999513    39.870824              52.017050                15.854796  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a21dc",
   "metadata": {},
   "source": [
    "# Download NFIP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33323f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T20:29:43.736876Z",
     "start_time": "2023-04-11T20:29:14.101436Z"
    }
   },
   "outputs": [],
   "source": [
    "# pol Policies for Camden\n",
    "# Call the pol API by fips\n",
    "# Camden, County NJ\n",
    "fips_list = ['34007']\n",
    "\n",
    "# Get the URL for querying policies\n",
    "url = \"https://www.fema.gov/api/open/v1/FimaNfipPolicies?$\"\n",
    "# Get the URL for # policies that meet request\n",
    "check = url + \"inlinecount=allpages&$top=1&$select=id&$\"\n",
    "\n",
    "\n",
    "# Loop through counties, \n",
    "# Get the data from the Pols API\n",
    "# Store in dataframe\n",
    "# Add to list\n",
    "# Concat all the dfs\n",
    "\n",
    "# List for Pols DFs\n",
    "pol_df_list = []\n",
    "\n",
    "# NFIP API usage adapts R code here: https://docs.ropensci.org/rfema/\n",
    "# And follows OpenFEMA guide: \n",
    "# https://www.fema.gov/about/openfema/working-with-large-data-sets#app-a\n",
    "\n",
    "for fips in fips_list:\n",
    "    # County endpoint\n",
    "    c_end = \"filter=countyCode%20eq%20%27\" + fips + \"%27\"\n",
    "    \n",
    "    # First, get the total number of records\n",
    "    records = requests.get(check + c_end)\n",
    "    n_rec = pd.json_normalize(records.json())['metadata.count'][0]\n",
    "    \n",
    "    # Get iterations needed (1,000 record limit)\n",
    "    iterations = math.ceil(n_rec / 1000)\n",
    "    \n",
    "    # Now, download 1,000 records at a time and store in list\n",
    "    # Loop through required iterations and keep appending policy \n",
    "    # data from the GET request to the pol_df_list\n",
    "    for i in range(iterations):\n",
    "        skip_str = \"&$skip=\" + str(i*1000)\n",
    "    \n",
    "        # GET Request\n",
    "        pol_get = requests.get(url + c_end + skip_str)\n",
    "\n",
    "        # Temp data frame\n",
    "        temp = pd.json_normalize(pol_get.json()['FimaNfipPolicies'])\n",
    "\n",
    "        # Add to list\n",
    "        pol_df_list.append(temp)\n",
    "\n",
    "# Concat\n",
    "nfip_pol = pd.concat(pol_df_list, axis=0)\n",
    "\n",
    "# Write to file\n",
    "nfip_pol.to_parquet(join(fr, 'exposure', 'nfip_pols.pqt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13b482c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T20:44:22.121531Z",
     "start_time": "2023-04-11T20:44:20.436086Z"
    }
   },
   "outputs": [],
   "source": [
    "# NFIP Claims for Camden\n",
    "# claim claimicies for Camden\n",
    "# Call the claim API by fips\n",
    "# Camden, County NJ\n",
    "fips_list = ['34007']\n",
    "\n",
    "# Get the URL for querying claimicies\n",
    "url = \"https://www.fema.gov/api/open/v1/FimaNfipClaims?$\"\n",
    "# Get the URL for # claimicies that meet request\n",
    "check = url + \"inlinecount=allpages&$top=1&$select=id&$\"\n",
    "\n",
    "\n",
    "# Loop through counties, \n",
    "# Get the data from the claims API\n",
    "# Store in dataframe\n",
    "# Add to list\n",
    "# Concat all the dfs\n",
    "\n",
    "# List for claims DFs\n",
    "claim_df_list = []\n",
    "\n",
    "# NFIP API usage adapts R code here: https://docs.ropensci.org/rfema/\n",
    "# And follows OpenFEMA guide: \n",
    "# https://www.fema.gov/about/openfema/working-with-large-data-sets#app-a\n",
    "\n",
    "for fips in fips_list:\n",
    "    # County endpoint\n",
    "    c_end = \"filter=countyCode%20eq%20%27\" + fips + \"%27\"\n",
    "    \n",
    "    # First, get the total number of records\n",
    "    records = requests.get(check + c_end)\n",
    "    n_rec = pd.json_normalize(records.json())['metadata.count'][0]\n",
    "    \n",
    "    # Get iterations needed (1,000 record limit)\n",
    "    iterations = math.ceil(n_rec / 1000)\n",
    "    \n",
    "    # Now, download 1,000 records at a time and store in list\n",
    "    # Loop through required iterations and keep appending claimicy \n",
    "    # data from the GET request to the claim_df_list\n",
    "    for i in range(iterations):\n",
    "        skip_str = \"&$skip=\" + str(i*1000)\n",
    "    \n",
    "        # GET Request\n",
    "        claim_get = requests.get(url + c_end + skip_str)\n",
    "\n",
    "        # Temp data frame\n",
    "        temp = pd.json_normalize(claim_get.json()['FimaNfipClaims'])\n",
    "\n",
    "        # Add to list\n",
    "        claim_df_list.append(temp)\n",
    "\n",
    "# Concat\n",
    "nfip_claim = pd.concat(claim_df_list, axis=0)\n",
    "\n",
    "# Write to file\n",
    "nfip_claim.to_parquet(join(fr, 'exposure', 'nfip_claims.pqt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e83940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add all data sources currently in keller-lab/data\n",
    "# Remove those data sources from that repo, makes sense\n",
    "# to instead use project by project data model\n",
    "# since we need the data accessible for reproducibility\n",
    "# HMGP, IHP, PA\n",
    "# Also Camden County NFHL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb22f3",
   "metadata": {},
   "source": [
    "# Download Camden County Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "50729ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T22:29:55.961811Z",
     "start_time": "2023-04-11T22:29:46.487448Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid field type <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 56\u001b[0m\n\u001b[1;32m     51\u001b[0m pars_geo \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pars,\n\u001b[1;32m     52\u001b[0m                             crs\u001b[38;5;241m=\u001b[39mEPSG,\n\u001b[1;32m     53\u001b[0m                             geometry\u001b[38;5;241m=\u001b[39mpars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Write data to file\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mpars_geo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexposure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpc.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGPKG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jumbo/keller-lab/Applications/miniconda3/envs/gc_elev/lib/python3.10/site-packages/geopandas/geodataframe.py:1203\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;124;03m>>> gdf.to_file('dataframe.shp', mode=\"a\")  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1203\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jumbo/keller-lab/Applications/miniconda3/envs/gc_elev/lib/python3.10/site-packages/geopandas/io/file.py:545\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn names longer than 10 characters will be truncated when saved to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mESRI Shapefile.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    541\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[43m_to_file_fiona\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    547\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/jumbo/keller-lab/Applications/miniconda3/envs/gc_elev/lib/python3.10/site-packages/geopandas/io/file.py:575\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[0;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m     crs_wkt \u001b[38;5;241m=\u001b[39m crs\u001b[38;5;241m.\u001b[39mto_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWKT1_GDAL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    573\u001b[0m     filename, mode\u001b[38;5;241m=\u001b[39mmode, driver\u001b[38;5;241m=\u001b[39mdriver, crs_wkt\u001b[38;5;241m=\u001b[39mcrs_wkt, schema\u001b[38;5;241m=\u001b[39mschema, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    574\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m colxn:\n\u001b[0;32m--> 575\u001b[0m     \u001b[43mcolxn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterecords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jumbo/keller-lab/Applications/miniconda3/envs/gc_elev/lib/python3.10/site-packages/fiona/collection.py:361\u001b[0m, in \u001b[0;36mCollection.writerecords\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection not open for writing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget_length()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1291\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.writerecs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:466\u001b[0m, in \u001b[0;36mfiona.ogrext.OGRFeatureBuilder.build\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid field type <class 'list'>"
     ]
    }
   ],
   "source": [
    "# Parcels\n",
    "par_df_list = []\n",
    "\n",
    "# Data is in epsg: 3424\n",
    "EPSG = '3424'\n",
    "\n",
    "# Store base URL\n",
    "par_url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/Parcel_Data_2021_Redacted/FeatureServer/1/query?outFields=*\"\n",
    "close_str = \"&f=geojson\"\n",
    "\n",
    "# Filter on municipality\n",
    "mun_str = \"&where=MUNICIPALITY%3D%27GLOUCESTER+CITY%27\"\n",
    "# Record count, 2000 at a time\n",
    "rec_str = \"&resultRecordCount=2000\"\n",
    "# Update resultOffset by 2000 at a time\n",
    "rec_n = 2000\n",
    "\n",
    "# Get number of records\n",
    "num_rec_url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/Parcel_Data_2021_Redacted/FeatureServer/1/query?where=MUNICIPALITY%3D%27GLOUCESTER+CITY%27&returnCountOnly=true&f=json\"\n",
    "num_r = requests.get(num_rec_url).json()['count']\n",
    "\n",
    "# Get iterations needed \n",
    "iterations = math.ceil(num_r / rec_n)\n",
    "\n",
    "# Now, download 2,000 records at a time and store in list\n",
    "# Loop through required iterations and keep appending claimicy \n",
    "# data from the GET request to the claim_df_list\n",
    "for i in range(iterations):\n",
    "    skip_str = \"&resultOffset=\" + str(i*rec_n)\n",
    "\n",
    "    # GET Request\n",
    "    par_get = requests.get(par_url + mun_str + skip_str + rec_str + close_str)\n",
    "\n",
    "    # Temp data frame\n",
    "    temp = par_get.json()['features']\n",
    "    temp_df = pd.json_normalize(temp)\n",
    "    temp_geo = [shape(i['geometry']) for i in temp]\n",
    "\n",
    "    # Geodataframe with temp_df & temp_geo linked\n",
    "    par_geo = gpd.GeoDataFrame(temp_df,\n",
    "                               crs=EPSG,\n",
    "                               geometry=temp_geo) \n",
    "\n",
    "    # Add to list\n",
    "    par_df_list.append(par_geo)\n",
    "\n",
    "# Concat\n",
    "pars = pd.concat(par_df_list, axis=0)\n",
    "\n",
    "# Get back to geodataframe\n",
    "pars_geo = gpd.GeoDataFrame(pars,\n",
    "                            crs=EPSG,\n",
    "                            geometry=pars['geometry'])\n",
    "\n",
    "# Drop type, id, geometry.type, geometry.coordinates\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "pars_geo = pars_geo.drop(columns=drop_col)\n",
    "\n",
    "# Write data to file\n",
    "pars_geo.to_file(join(fr, 'exposure', 'pc.gpkg'),\n",
    "                 driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4d9e6c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T23:33:33.995356Z",
     "start_time": "2023-04-11T23:33:33.245105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tracts\n",
    "# tract Codes\n",
    "url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/CensusTracts/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "\n",
    "# Data in epsg: 3424\n",
    "EPSG = '3424'\n",
    "\n",
    "# GET Request\n",
    "tract_get = requests.get(url)\n",
    "\n",
    "# No loop needed, just the one tracticipality\n",
    "temp = tract_get.json()['features']\n",
    "temp_df = pd.json_normalize(temp)\n",
    "temp_geo = [shape(i['geometry']) for i in temp]\n",
    "\n",
    "# Final df\n",
    "tract_geo = gpd.GeoDataFrame(temp_df,\n",
    "                           crs=EPSG,\n",
    "                           geometry=temp_geo)\n",
    "\n",
    "# Drop type, id, geometry.type, geometry.coordinates\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "tract_geo = tract_geo.drop(columns=drop_col)\n",
    "\n",
    "# Write data to file\n",
    "tract_geo.to_file(join(fr, 'ref', 'tracts.gpkg'),\n",
    "                driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e58790a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T23:32:44.029119Z",
     "start_time": "2023-04-11T23:32:42.419738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zip Codes\n",
    "url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/Zip_Codes/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "\n",
    "# Data in epsg: 3424\n",
    "EPSG = '3424'\n",
    "\n",
    "# GET Request\n",
    "zip_get = requests.get(url)\n",
    "\n",
    "# No loop needed, just the one zipicipality\n",
    "temp = zip_get.json()['features']\n",
    "temp_df = pd.json_normalize(temp)\n",
    "temp_geo = [shape(i['geometry']) for i in temp]\n",
    "\n",
    "# Final df\n",
    "zip_geo = gpd.GeoDataFrame(temp_df,\n",
    "                           crs=EPSG,\n",
    "                           geometry=temp_geo)\n",
    "\n",
    "# Drop type, id, geometry.type, geometry.coordinates\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "zip_geo = zip_geo.drop(columns=drop_col)\n",
    "\n",
    "# Write data to file\n",
    "zip_geo.to_file(join(fr, 'ref', 'zipcodes.gpkg'),\n",
    "                driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cca8026f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T23:30:07.996017Z",
     "start_time": "2023-04-11T23:30:06.667218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Municipalities for Camden (useful for clipping other data to GC)\n",
    "url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/CamdenCountyMunicipalLayer/FeatureServer/0/query?f=geojson&where=(NAMELSAD%20IN%20(%27Gloucester%20City%20city%27))&outFields=*\"\n",
    "\n",
    "# Data is in epsg: 26918\n",
    "EPSG = '26918'\n",
    "\n",
    "# GET Request\n",
    "mun_get = requests.get(url)\n",
    "\n",
    "# No loop needed, just the one municipality\n",
    "temp = mun_get.json()['features']\n",
    "temp_df = pd.json_normalize(temp)\n",
    "temp_geo = [shape(i['geometry']) for i in temp]\n",
    "\n",
    "# Final df\n",
    "mun_geo = gpd.GeoDataFrame(temp_df,\n",
    "                           crs=EPSG,\n",
    "                           geometry=temp_geo)\n",
    "\n",
    "# Drop type, id, geometry.type, geometry.coordinates\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "mun_geo = mun_geo.drop(columns=drop_col)\n",
    "\n",
    "# Reproject to 3424\n",
    "OUT_EPSG = '3424'\n",
    "mun_geo = mun_geo.to_crs(epsg=OUT_EPSG)\n",
    "\n",
    "# Write data to file\n",
    "mun_geo.to_file(join(fr, 'ref', 'city_clip.gpkg'),\n",
    "                driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7fd117a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T23:16:17.778971Z",
     "start_time": "2023-04-11T23:16:17.151445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Land Uses\n",
    "url = \"https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/DVRPC_2010_Land_Use/FeatureServer/0/query?f=geojson&where=(Mun_Name%20IN%20(%27Gloucester%20City%27))&outFields=*\"\n",
    "# Data is in epsg: 3424\n",
    "EPSG = '3424'\n",
    "\n",
    "# GET Request\n",
    "lu_get = requests.get(url)\n",
    "\n",
    "# No loop needed because only ~100 records\n",
    "# Temp data frame\n",
    "temp = lu_get.json()['features']\n",
    "temp_df = pd.json_normalize(temp)\n",
    "temp_geo = [shape(i['geometry']) for i in temp]\n",
    "\n",
    "# Final df\n",
    "lu_geo = gpd.GeoDataFrame(temp_df,\n",
    "                          crs=EPSG,\n",
    "                          geometry=temp_geo)\n",
    "   \n",
    "\n",
    "# Drop type, id, geometry.type, geometry.coordinates\n",
    "drop_col = ['type', 'id', 'geometry.type', 'geometry.coordinates']\n",
    "lu_geo = lu_geo.drop(columns=drop_col)\n",
    "\n",
    "# Write data to file\n",
    "lu_geo.to_file(join(fr, 'exposure', 'landuse.gpkg'),\n",
    "               driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41efff2",
   "metadata": {},
   "source": [
    "# Download Social Vulnerability Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5399841d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:53:37.131940Z",
     "start_time": "2023-04-11T19:53:36.418510Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOAA SOVI\n",
    "url = 'https://coast.noaa.gov/htdata/SocioEconomic/SoVI2010/SoVI_2010_NJ.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b9b0ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:53:45.566998Z",
     "start_time": "2023-04-11T19:53:45.512944Z"
    }
   },
   "outputs": [],
   "source": [
    "# NJ env. burd communities\n",
    "url = \"https://services1.arcgis.com/QWdNfRs7lkPq4g4Q/ArcGIS/rest/services/Overburdened_Communities_2020_Hosted/FeatureServer/0/query?where=NAME%3D%27Gloucester+City%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53c5e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T19:54:05.847566Z",
     "start_time": "2023-04-11T19:54:05.619626Z"
    }
   },
   "outputs": [],
   "source": [
    "# CEJST (download later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff58608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gc_elev",
   "language": "python",
   "name": "gc_elev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

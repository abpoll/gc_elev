{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9630f49e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T17:35:33.677749Z",
     "start_time": "2023-04-12T17:35:33.474792Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff1249c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T17:35:39.577019Z",
     "start_time": "2023-04-12T17:35:33.682482Z"
    }
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import glob\n",
    "from os.path import join\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "from pyproj import CRS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec570f2",
   "metadata": {},
   "source": [
    "# Move .zip Directories to Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475958ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T17:45:03.330951Z",
     "start_time": "2023-04-12T17:45:02.932243Z"
    }
   },
   "outputs": [],
   "source": [
    "# It could make sense to have a lib/ style directory\n",
    "# like PLACES has for common functionality\n",
    "# and this code block would be useful there for getting\n",
    "# a fr() path\n",
    "\n",
    "# Get the absolute path to the precal_hazard directory\n",
    "# Which is two directories above notebooks/exploration/\n",
    "abs_dir = os.path.abspath(Path(os.getcwd()).parents[1])\n",
    "# Get raw data directory\n",
    "fr = join(abs_dir, 'data', 'raw')\n",
    "# Get interim data directory\n",
    "fi = join(abs_dir, 'data', 'interim')\n",
    "# Get processed data directory\n",
    "fp = join(abs_dir, 'data', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd79409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:06:24.774116Z",
     "start_time": "2023-04-12T13:06:24.046940Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each .zip directory in fr\n",
    "# Create needed subdirectories in interim/\n",
    "# Unzip in the appropriate interim/ subdirectory\n",
    "\n",
    "for path in Path(fr).rglob('*.zip'):\n",
    "    # Avoid hidden files and files in directories\n",
    "    if path.name[0] != '.':\n",
    "        # Get root for the directory this .zip file is in\n",
    "        zip_root = path.relative_to(fr).parents[0]\n",
    "\n",
    "        # Get path to interim/zip_root\n",
    "        zip_to_path = join(fi, zip_root)\n",
    "\n",
    "        # Make directory, including parents\n",
    "        # No need to check if directory exists bc\n",
    "        # it is only created when this script is run\n",
    "        Path(zip_to_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Unzip to zip_to_path\n",
    "        with ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(zip_to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b7f76",
   "metadata": {},
   "source": [
    "# Clip Raw Data to Location Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fc4058e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:41:01.870000Z",
     "start_time": "2023-04-12T13:41:00.983027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reference the GC clip file\n",
    "boundary_filep = join(fr, 'ref', 'city_clip.gpkg')\n",
    "# Read boundary\n",
    "boundary = gpd.read_file(boundary_filep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff78f7",
   "metadata": {},
   "source": [
    "## NSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516e1af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:18:28.429960Z",
     "start_time": "2023-04-12T13:18:26.142459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read full NSI from all the counties\n",
    "nsi_filep = join(fr, 'exposure', 'nsi.pqt')\n",
    "# Read and reset index\n",
    "nsi_full = pd.read_parquet(nsi_filep).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c6ac6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:20:25.830422Z",
     "start_time": "2023-04-12T13:20:24.866682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to geodataframe\n",
    "geometry = gpd.points_from_xy(nsi_full['properties.x'],\n",
    "                            nsi_full['properties.y'])\n",
    "# The NSI CRS is EPSG 4326\n",
    "nsi_gdf_f = gpd.GeoDataFrame(nsi_full, geometry=geometry,\n",
    "                             crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "220b3bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:41:24.106604Z",
     "start_time": "2023-04-12T13:41:23.431499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Project nsi_gdf_f coordinates to EPSG 3424 so that they\n",
    "# match the boundary CRS\n",
    "nsi_gdf_f = nsi_gdf_f.to_crs(boundary.crs)\n",
    "\n",
    "# Use spatial join to get nsi locations within location boundary\n",
    "nsi_gdf = gpd.sjoin(nsi_gdf_f, boundary[['geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "285fbf00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:43:33.960478Z",
     "start_time": "2023-04-12T13:43:33.518472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the following columns\n",
    "drop_cols = ['type', 'geometry.type', 'geometry.coordinates', 'index_right']\n",
    "nsi_gdf = nsi_gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in nsi_gdf.columns]\n",
    "nsi_gdf.columns = col_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d564cf8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T13:43:42.182218Z",
     "start_time": "2023-04-12T13:43:39.808056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the NSI data to interim\n",
    "int_exp_filep = join(fi, 'exposure')\n",
    "Path(int_exp_filep).mkdir(parents=True, exist_ok=True)\n",
    "nsi_gdf.to_file(join(int_exp_filep, 'nsi.gpkg'), driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5633d",
   "metadata": {},
   "source": [
    "## Camden Depth Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9765fb36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:01:52.069442Z",
     "start_time": "2023-04-12T14:01:51.253325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Depth grid reference\n",
    "dg_filep = join(fr, 'hazard', 'camden_depthgrid', 'cst_dpth01pct.tif')\n",
    "\n",
    "# Reprojected temp file\n",
    "# Ensure directory exists\n",
    "dg_reproj_dir = join(fi, 'hazard', 'tmp')\n",
    "Path(dg_reproj_dir).mkdir(parents=True, exist_ok=True)\n",
    "dg_reproj_filep = join(dg_reproj_dir, 'cst_depth01_r.tif')\n",
    "\n",
    "# Reproj & clipped file\n",
    "# Goes in interim\n",
    "dg_out_filep = join(fi, 'hazard', 'cst_depth01.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73940b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:02:22.566052Z",
     "start_time": "2023-04-12T14:02:20.642709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reproject depth grid to epsg: 3424\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "# Straight from the source\n",
    "# https://rasterio.readthedocs.io/en/stable/topics/reproject.html\n",
    "\n",
    "dst_crs = 'EPSG:3424'\n",
    "\n",
    "with rasterio.open(dg_filep) as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    with rasterio.open(dg_reproj_filep, 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11b9998e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:04:38.270950Z",
     "start_time": "2023-04-12T14:04:37.724182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clip depth grid to GC boundaries\n",
    "import rasterio.mask\n",
    "# Straight from the source\n",
    "# https://rasterio.readthedocs.io/en/stable/topics/masking-by-shapefile.html\n",
    "\n",
    "# Replace shapes with boundary['geometry']\n",
    "\n",
    "with rasterio.open(dg_reproj_filep) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, boundary['geometry'],\n",
    "                                                  crop=True)\n",
    "    out_meta = src.meta\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "with rasterio.open(dg_out_filep, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ac556",
   "metadata": {},
   "source": [
    "## Camden Flood Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21c340a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:27:57.120210Z",
     "start_time": "2023-04-12T14:27:29.021471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load nfhl.gdb, flood zone layer\n",
    "nfhl_filep = join(fr, 'hazard', 'nfhl.gdb')\n",
    "nfhl = gpd.read_file(nfhl_filep, layer='S_Fld_Haz_Ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4cd0ea9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:28:59.614948Z",
     "start_time": "2023-04-12T14:28:41.137554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reproject and clip\n",
    "nfhl_r = nfhl.to_crs(boundary.crs)\n",
    "nfhl_clip = gpd.clip(nfhl_r, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f532060c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:34:10.009901Z",
     "start_time": "2023-04-12T14:34:09.150369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep FLD_ZONE, FLD_AR_ID, STATIC_BFE, geometry\n",
    "keep_cols = ['FLD_ZONE', 'FLD_AR_ID', 'STATIC_BFE', 'ZONE_SUBTY',\n",
    "             'geometry']\n",
    "nfhl_f = nfhl_clip[keep_cols]\n",
    "\n",
    "# Adjust .2 pct X zones to X_500\n",
    "nfhl_f.loc[nfhl_f['ZONE_SUBTY'] == '.2 PCT ANNUAL CHANCE FLOOD HAZARD',\n",
    "           'FLD_ZONE'] = nfhl_f['FLD_ZONE'] + '_500'\n",
    "\n",
    "# Update column names\n",
    "# Lower case\n",
    "nfhl_f.columns = [x.lower() for x in nfhl_f.columns]\n",
    "\n",
    "# Drop ZONE_SUBTY\n",
    "nfhl_f = nfhl_f.drop(columns=['zone_subty'])\n",
    "\n",
    "# Write file\n",
    "nfhl_out_filep = join(fi, 'hazard', 'floodzones.gpkg')\n",
    "nfhl_f.to_file(nfhl_out_filep, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3379d",
   "metadata": {},
   "source": [
    "## CE JST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f31c98c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:55:00.445499Z",
     "start_time": "2023-04-12T14:54:37.521353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filepath\n",
    "ce_filep = join(fr, 'vulnerability', 'social', 'cejst', 'usa.shp')\n",
    "# Read file\n",
    "ce_geo = gpd.read_file(ce_filep)\n",
    "# Subset to camden county\n",
    "ce_camden = ce_geo[(ce_geo['SF'] == 'New Jersey') &\n",
    "                   (ce_geo['CF'] == 'Camden County')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62155b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T15:10:35.143487Z",
     "start_time": "2023-04-12T15:10:34.025264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reproject\n",
    "ce_camden = ce_camden.to_crs(boundary.crs)\n",
    "\n",
    "# Clip\n",
    "ce_gc = gpd.clip(ce_camden, boundary)\n",
    "\n",
    "# Write file\n",
    "ce_gc_out_filep = join(fi, 'vulnerability', 'cejst.gpkg')\n",
    "ce_gc.to_file(ce_gc_out_filep, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace13ccf",
   "metadata": {},
   "source": [
    "## Ref files (bg, tract, zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1743b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T15:27:56.052414Z",
     "start_time": "2023-04-12T15:27:52.979434Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of raw files\n",
    "raw_filep = ['blockgroups/tl_2021_34_bg.shp',\n",
    "             'tracts.gpkg', 'zipcodes.gpkg']\n",
    "\n",
    "# List of output files\n",
    "out_filep = ['bg.gpkg', 'tracts.gpkg', 'zips.gpkg']\n",
    "\n",
    "# Input file directory\n",
    "filedir_in = join(fr, 'ref')\n",
    "\n",
    "# Output file directory\n",
    "filedir_out = join(fp, 'ref')\n",
    "\n",
    "# Loop through files\n",
    "# Reproject each (if needed)\n",
    "# Clip and write\n",
    "for i, fp in enumerate(raw_filep):\n",
    "    input_filep = join(filedir_in, fp)\n",
    "    output_filep = join(filedir_out, out_filep[i])\n",
    "    \n",
    "    ref = gpd.read_file(input_filep)\n",
    "    \n",
    "    if ref.crs != boundary.crs:\n",
    "        ref = ref.to_crs(boundary.crs)\n",
    "    \n",
    "    ref_clip = gpd.clip(ref, boundary)\n",
    "    \n",
    "    ref_clip.to_file(output_filep, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50e303",
   "metadata": {},
   "source": [
    "# Link Block Groups to LMI data and write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "561fc6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T18:14:45.559378Z",
     "start_time": "2023-04-12T18:14:43.838883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Block Groups\n",
    "bg_filep = join(fp, 'ref', 'bg.gpkg')\n",
    "bg = gpd.read_file(bg_filep)\n",
    "\n",
    "# Load lmi\n",
    "lmi_filep = join(fr, 'vulnerability', 'social', 'lmi_bg_2015.csv')\n",
    "lmi = pd.read_csv(lmi_filep,\n",
    "                  dtype={'County': 'str',\n",
    "                         'State': 'str',\n",
    "                         'Tract': 'str',\n",
    "                         'Blckgrp': 'str'})\n",
    "\n",
    "lmi_camden = lmi[(lmi['State'] == '34') &\n",
    "                 (lmi['County'] == '007')]\n",
    "\n",
    "# Filter lmi\n",
    "# Merge on last 12 characters\n",
    "lmi['GEOID'] = lmi['GEOID'].str[-12:]\n",
    "# Merge and write out\n",
    "lmi_bg = bg[['GEOID', 'geometry']].merge(lmi, on='GEOID', how='inner')\n",
    "lmi_bg_out_dir = join(fp, 'vulnerability', 'social')\n",
    "lmi_bg_out_filep = join(lmi_bg_out_dir, 'lmi_bg.gpkg')\n",
    "Path(lmi_bg_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "lmi_bg.to_file(lmi_bg_out_filep, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be84326",
   "metadata": {},
   "source": [
    "# Get Processed Structure Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281164e",
   "metadata": {},
   "source": [
    "## Clean and Filter Parcel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a645ba3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:09:04.649341Z",
     "start_time": "2023-04-12T19:09:01.900013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read pc.gpkg\n",
    "pc_filep = join(fr, 'exposure', 'pc.gpkg')\n",
    "pc = gpd.read_file(pc_filep)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in pc.columns]\n",
    "pc.columns = col_updates\n",
    "\n",
    "# Subset to relevant columns\n",
    "keep_cols = ['OBJECTID', 'PAMS_PIN', 'UNIQUEID',\n",
    "             'HNUM', 'HADD', 'Location',\n",
    "             'Owner_Street', 'Owner_Csz',\n",
    "             'Class', 'Bldg_Desc',\n",
    "             'Land_Value', 'Impr_Value', 'Net_Value',\n",
    "             'Sale_Date', 'Sale_Price',\n",
    "             'Facility_Name',\n",
    "             'Disabled', 'Seniors',\n",
    "             'Year_Built']\n",
    "\n",
    "# Change value cols to float\n",
    "\n",
    "# Check for Location vs. Owner_Street and assign\n",
    "# owner occupied\n",
    "\n",
    "# Sale_Date datetime m/day/year\n",
    "\n",
    "# Sale price as float\n",
    "\n",
    "# Disabled & Elderly deductions as indicators \n",
    "# for some vulnerability information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa2405",
   "metadata": {},
   "source": [
    "## Link NSI to Other Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a9aa2b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:06:20.543395Z",
     "start_time": "2023-04-12T19:06:19.460323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read NSI\n",
    "nsi_filep = join(fi, 'exposure', 'nsi.gpkg')\n",
    "nsi = gpd.read_file(nsi_filep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "045a0ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:09:07.893365Z",
     "start_time": "2023-04-12T19:09:07.253281Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = gpd.sjoin(nsi, pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87bf7d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:19:16.979827Z",
     "start_time": "2023-04-12T19:19:16.034547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fd_id</th>\n",
       "      <th>bid</th>\n",
       "      <th>occtype</th>\n",
       "      <th>st_damcat</th>\n",
       "      <th>bldgtype</th>\n",
       "      <th>found_type</th>\n",
       "      <th>cbfips</th>\n",
       "      <th>pop2amu65</th>\n",
       "      <th>pop2amo65</th>\n",
       "      <th>pop2pmu65</th>\n",
       "      <th>...</th>\n",
       "      <th>SP_SF</th>\n",
       "      <th>LEADLOT</th>\n",
       "      <th>New_Record</th>\n",
       "      <th>Error</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>DeedLink</th>\n",
       "      <th>Zoning</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [fd_id, bid, occtype, st_damcat, bldgtype, found_type, cbfips, pop2amu65, pop2amo65, pop2pmu65, pop2pmo65, sqft, num_story, ftprntid, ftprntsrc, students, found_ht, val_struct, val_cont, val_vehic, source, med_yr_blt, firmzone, o65disable, u65disable, x, y, ground_elv, ground_elv_m, geometry, index_right, OBJECTID, PAMS_PIN, MUN, BLOCK, LOT, QCODE, LASTUPDATE, MUNICIPALITY, MAPSHTNO, IMAGEFILE, PCODE, NOTES, HBLOCK, HLOT, DATASOURCE, SOURCEDATE, UNIQUEID, HNUM, HADD, PAMSPIN, Old_Block, Old_Lot, Old_Qual, Location, Owner_Name, Owner_Street, Owner_Csz, Class, Land_Value, Exmpt1_Cd, Exmpt1_Value, Impr_Value, Net_Value, Partial_Asmt, Sale_Date, Sale_Book, Sale_Page, Sale_Price, Sale_Nu, Bank_Cd, Map_Page, Bldg_Desc, Lot_Desc, Additional_Lots, New_AddLots, New_RecordLeadLot, Additional_Lots2, Epl_Owner, Epl_Use, Epl_Desc, Initial_Filing_Date, Further_Filing_Date, Statute, Facility_Name, Disabled, SurvSp, Seniors, Vets, Widows, Sp_Tax_Cd1, Sp_Tax_Cd2, Last_Yr_Tax, Curr_Yr_Tax, Last_Yr_MunTax, Curr_Yr_MunTax, Number_Of_Owners, Deduction_Amount, Update_Date, Neigh, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 120 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp['Location'] == '216 SOMERSET ST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e2a6e3be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:10:51.030310Z",
     "start_time": "2023-04-12T19:10:50.554377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fd_id</th>\n",
       "      <th>bid</th>\n",
       "      <th>occtype</th>\n",
       "      <th>st_damcat</th>\n",
       "      <th>bldgtype</th>\n",
       "      <th>found_type</th>\n",
       "      <th>cbfips</th>\n",
       "      <th>pop2amu65</th>\n",
       "      <th>pop2amo65</th>\n",
       "      <th>pop2pmu65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>550381727</td>\n",
       "      <td>87F6VVXG+428-3-2-2-3</td>\n",
       "      <td>RES1-1SWB</td>\n",
       "      <td>RES</td>\n",
       "      <td>W</td>\n",
       "      <td>B</td>\n",
       "      <td>340076110005001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>550381730</td>\n",
       "      <td>87F6VVXG+428-3-3-3-4</td>\n",
       "      <td>RES1-2SWB</td>\n",
       "      <td>RES</td>\n",
       "      <td>W</td>\n",
       "      <td>B</td>\n",
       "      <td>340076110005001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fd_id                   bid    occtype st_damcat bldgtype  \\\n",
       "1825  550381727  87F6VVXG+428-3-2-2-3  RES1-1SWB       RES        W   \n",
       "1828  550381730  87F6VVXG+428-3-3-3-4  RES1-2SWB       RES        W   \n",
       "\n",
       "     found_type           cbfips  pop2amu65  pop2amo65  pop2pmu65  \n",
       "1825          B  340076110005001          2          0          1  \n",
       "1828          B  340076110005001          3          1          1  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp['Location'] == '218 SOMERSET ST'].iloc[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a3077f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:11:40.878420Z",
     "start_time": "2023-04-12T19:11:40.441930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop2pmo65</th>\n",
       "      <th>sqft</th>\n",
       "      <th>num_story</th>\n",
       "      <th>ftprntid</th>\n",
       "      <th>ftprntsrc</th>\n",
       "      <th>students</th>\n",
       "      <th>found_ht</th>\n",
       "      <th>val_struct</th>\n",
       "      <th>val_cont</th>\n",
       "      <th>val_vehic</th>\n",
       "      <th>source</th>\n",
       "      <th>med_yr_blt</th>\n",
       "      <th>firmzone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34007_187999</td>\n",
       "      <td>NGA</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184901.582</td>\n",
       "      <td>92450.791</td>\n",
       "      <td>27000</td>\n",
       "      <td>P</td>\n",
       "      <td>1939</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>1</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34007_188005</td>\n",
       "      <td>Bing</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>298712.610</td>\n",
       "      <td>149356.305</td>\n",
       "      <td>27000</td>\n",
       "      <td>P</td>\n",
       "      <td>1939</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pop2pmo65    sqft  num_story      ftprntid ftprntsrc  students  \\\n",
       "1825          0  1056.0          1  34007_187999       NGA         0   \n",
       "1828          1  2378.0          2  34007_188005      Bing         0   \n",
       "\n",
       "      found_ht  val_struct    val_cont  val_vehic source  med_yr_blt firmzone  \n",
       "1825       2.0  184901.582   92450.791      27000      P        1939     None  \n",
       "1828       2.0  298712.610  149356.305      27000      P        1939     None  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp['Location'] == '218 SOMERSET ST'].iloc[:,10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4348271f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:21:25.076391Z",
     "start_time": "2023-04-12T19:21:24.212139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VCS</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Lot_Size</th>\n",
       "      <th>Style</th>\n",
       "      <th>UpdCd</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Sf_Area</th>\n",
       "      <th>Type_Use</th>\n",
       "      <th>Basement</th>\n",
       "      <th>Finbsmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000001185</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1900</td>\n",
       "      <td>None</td>\n",
       "      <td>08030</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>000001185</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1900</td>\n",
       "      <td>None</td>\n",
       "      <td>08030</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VCS  Zone   Lot_Size Style UpdCd Year_Built Sf_Area Type_Use Basement  \\\n",
       "1825  None  None  000001185  None    20       1900    None    08030     None   \n",
       "1828  None  None  000001185  None    20       1900    None    08030     None   \n",
       "\n",
       "     Finbsmt  \n",
       "1825    None  \n",
       "1828    None  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp['Location'] == '218 SOMERSET ST'].iloc[:,100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ba31bb28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:30:13.632588Z",
     "start_time": "2023-04-12T19:30:13.169526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exmpt1_Value</th>\n",
       "      <th>Impr_Value</th>\n",
       "      <th>Net_Value</th>\n",
       "      <th>Partial_Asmt</th>\n",
       "      <th>Sale_Date</th>\n",
       "      <th>Sale_Book</th>\n",
       "      <th>Sale_Page</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Sale_Nu</th>\n",
       "      <th>Bank_Cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>00000000</td>\n",
       "      <td>000046200</td>\n",
       "      <td>000063700</td>\n",
       "      <td>None</td>\n",
       "      <td>032619</td>\n",
       "      <td>11112</td>\n",
       "      <td>01604</td>\n",
       "      <td>000014000</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Exmpt1_Value Impr_Value  Net_Value Partial_Asmt Sale_Date Sale_Book  \\\n",
       "4103     00000000  000046200  000063700         None    032619     11112   \n",
       "\n",
       "     Sale_Page Sale_Price Sale_Nu Bank_Cd  \n",
       "4103     01604  000014000      26    None  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc[pc['Location'] == '216 SOMERSET ST'].iloc[:,30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9c220f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T19:30:09.369724Z",
     "start_time": "2023-04-12T19:30:08.960824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exmpt1_Value</th>\n",
       "      <th>Impr_Value</th>\n",
       "      <th>Net_Value</th>\n",
       "      <th>Partial_Asmt</th>\n",
       "      <th>Sale_Date</th>\n",
       "      <th>Sale_Book</th>\n",
       "      <th>Sale_Page</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Sale_Nu</th>\n",
       "      <th>Bank_Cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>00000000</td>\n",
       "      <td>000086800</td>\n",
       "      <td>000115600</td>\n",
       "      <td>None</td>\n",
       "      <td>033006</td>\n",
       "      <td>08176</td>\n",
       "      <td>00741</td>\n",
       "      <td>000147000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Exmpt1_Value Impr_Value  Net_Value Partial_Asmt Sale_Date Sale_Book  \\\n",
       "2768     00000000  000086800  000115600         None    033006     08176   \n",
       "\n",
       "     Sale_Page Sale_Price Sale_Nu Bank_Cd  \n",
       "2768     00741  000147000    None    None  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc[pc['Location'] == '218 SOMERSET ST'].iloc[:,30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678d615",
   "metadata": {},
   "source": [
    "## Write out Residential NSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0361b4ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T15:27:04.866194Z",
     "start_time": "2023-03-14T15:27:04.825214Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, process parcel data and write out\n",
    "# Next, link relevant parcel data with NSI \n",
    "# Merge reference files (bg, tract, zip) with NSI points\n",
    "# Link NSI data to lmi, cejst, etc.\n",
    "# Link NSI data to bfe, depth grids\n",
    "\n",
    "# There's filtering/cleaning\n",
    "# There's a series of attribute joins\n",
    "# There's a series of spatial joins\n",
    "\n",
    "# Want to write out all the id/var combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1285b394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T15:27:05.387672Z",
     "start_time": "2023-03-14T15:27:05.345384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.025',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0175',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.1',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.01',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.06',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0275',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.08',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.02',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.035',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.045',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.05',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0375',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0125',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.07',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0225',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.04',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.03',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.09',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.0325',\n",
       " '/jumbo/keller-lab/projects/icom/precal/precal_hazard/data/interim/hazard/output0.015']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haz_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "056810c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T15:38:57.320939Z",
     "start_time": "2023-03-14T15:38:46.601696Z"
    }
   },
   "outputs": [],
   "source": [
    "# metadata from .txt file\n",
    "# ncols         2276\n",
    "# nrows         1564\n",
    "# xllcorner     -75.4159722219145\n",
    "# yllcorner     40.0026388902255\n",
    "# cellsize      9.2592593e-05\n",
    "# NODATA_value  -9999\n",
    "\n",
    "# Prepare directory for writing out\n",
    "HAZ_OUT_DIR = join(fp, 'hazard', 'depths')\n",
    "Path(HAZ_OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Constant for peak_flood depth.txt\n",
    "DEPTH_FILEP = \"peak_flood_depth.txt\"\n",
    "\n",
    "# Constants from metadata\n",
    "EPSG = 4269\n",
    "NODATA = -9999\n",
    "NROWS = 1564\n",
    "RES = 9.2592593e-05\n",
    "XLL = -75.4159722219145\n",
    "YLL = 40.0026388902255\n",
    "# Get the CRS \n",
    "crs = CRS.from_user_input(EPSG)\n",
    "\n",
    "# Calculate the y coordinate for the origin\n",
    "# by adding the cell resolution * raster height (#rows)\n",
    "# to the y lower left coordinate\n",
    "# xll and yll mean x lower left and y lower left\n",
    "YUL = YLL + RES*NROWS\n",
    "\n",
    "# Get transform\n",
    "trans = rasterio.transform.from_origin(XLL,\n",
    "                                       YUL,\n",
    "                                       RES, RES)\n",
    "\n",
    "\n",
    "# Use \"output*\" wildcard in glob to find\n",
    "# all subdirectories in interim/hazard/\n",
    "# that have peak_flood_depth.txt files in them\n",
    "# Use numpy to load text, then reshape the data\n",
    "# Use rasterio to provide the CRS\n",
    "# The datum is NAD83, EPSG: 4269\n",
    "haz_filedir = join(fi, 'hazard')\n",
    "haz_dirs = glob.glob(join(haz_filedir, \"output*\"))\n",
    "\n",
    "# Loop through directories in haz_dirs\n",
    "# Convert each peak_flood_depth.txt\n",
    "# into a raster\n",
    "# Use the wildcard component\n",
    "# after \"output\" as the index\n",
    "for hd in haz_dirs:\n",
    "    haz_filep = join(hd, DEPTH_FILEP)\n",
    "    # Suffix correspondes to parameter\n",
    "    # values used to generate depths\n",
    "    # Useful to keep this in the processing/writing\n",
    "    # of files\n",
    "    file_suf = hd.split(\"output\")[1]\n",
    "\n",
    "    # Load peak_flood_depth.txt\n",
    "    fld_depths_in = np.loadtxt(haz_filep, skiprows=6)\n",
    "\n",
    "    # Unique filename for each depth grid\n",
    "    # Join haz_out_dir defined as a constant above\n",
    "    # with peak_fld_depth, the file_suf, and .tif\n",
    "    filename = 'peak_fld_depth_' + file_suf + '.tif'\n",
    "    haz_out_filep = join(HAZ_OUT_DIR, filename)\n",
    "\n",
    "    # Write raster \n",
    "    haz_r = rasterio.open(haz_out_filep, 'w', driver='GTiff',\n",
    "                          height=fld_depths_in.shape[0],\n",
    "                          width=fld_depths_in.shape[1],\n",
    "                          count=1, dtype=str(fld_depths_in.dtype),\n",
    "                          crs=crs, nodata=NODATA, transform=trans)\n",
    "\n",
    "    haz_r.write(fld_depths_in, 1)\n",
    "    haz_r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8acd66",
   "metadata": {},
   "source": [
    "## Link depths to structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3bb4393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:24:37.122318Z",
     "start_time": "2023-03-14T16:24:37.079378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peak_fld_depth_0.0375.tif',\n",
       " 'peak_fld_depth_0.0125.tif',\n",
       " 'peak_fld_depth_0.035.tif',\n",
       " 'peak_fld_depth_0.05.tif',\n",
       " 'peak_fld_depth_0.02.tif',\n",
       " 'peak_fld_depth_0.0275.tif',\n",
       " 'peak_fld_depth_0.025.tif',\n",
       " 'peak_fld_depth_0.0225.tif',\n",
       " 'peak_fld_depth_0.0175.tif',\n",
       " 'peak_fld_depth_0.0325.tif',\n",
       " 'peak_fld_depth_0.03.tif',\n",
       " 'peak_fld_depth_0.04.tif',\n",
       " 'peak_fld_depth_0.1.tif',\n",
       " 'peak_fld_depth_0.07.tif',\n",
       " 'peak_fld_depth_0.045.tif',\n",
       " 'peak_fld_depth_0.09.tif',\n",
       " 'peak_fld_depth_0.08.tif',\n",
       " 'peak_fld_depth_0.01.tif',\n",
       " 'peak_fld_depth_0.06.tif',\n",
       " 'peak_fld_depth_0.015.tif']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b26f65c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:25:44.719812Z",
     "start_time": "2023-03-14T16:25:09.109307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in NSI data\n",
    "INT_EXP_FILEP = join(fi, 'exposure')\n",
    "nsi_gdf = gpd.read_file(join(INT_EXP_FILEP, 'nsi.gpkg'))\n",
    "\n",
    "# Get coordinate list\n",
    "coord_list = [(x, y) for x, y in\n",
    "              zip(nsi_gdf['geometry'].x,\n",
    "                  nsi_gdf['geometry'].y)]\n",
    "\n",
    "# List of depth series\n",
    "depth_list = []\n",
    "\n",
    "# For each depth raster, link up unique property\n",
    "# coordinates with the corresponding depth values\n",
    "# Write out file of coord/id index & depth_suf columns\n",
    "depth_filenames = os.listdir(HAZ_OUT_DIR)\n",
    "\n",
    "for d_fn in depth_filenames:\n",
    "    # Filepath and load\n",
    "    d_grid_fp = join(HAZ_OUT_DIR, d_fn)\n",
    "    # Open the depth raster in read mode\n",
    "    d_grid = rasterio.open(d_grid_fp)\n",
    "\n",
    "    # Get the suffix\n",
    "    # First, get the pre .tif str component\n",
    "    filepre = d_fn.split('.tif')[0]\n",
    "    # Then get last element splitting on \"_\"\n",
    "    d_suf = filepre.split('_')[-1]\n",
    "\n",
    "    # Sample points from the raster based on nsi coordinates\n",
    "    # Get sampled values from pixels\n",
    "    sampled_depths = [x[0] for x in d_grid.sample(coord_list)]\n",
    "\n",
    "    # Store as series with name\n",
    "    # Index by fd_id\n",
    "    # depth_d_suf\n",
    "    depth_series = pd.Series(sampled_depths,\n",
    "                             index=nsi_gdf['fd_id'],\n",
    "                             name='depth_' + d_suf)\n",
    "\n",
    "    # Convert depth to ft\n",
    "    depth_series = depth_series * 3.281\n",
    "\n",
    "    # Store in list\n",
    "    depth_list.append(depth_series)\n",
    "    \n",
    "# Concat into dataframe\n",
    "depths = pd.concat(depth_list, axis=1)\n",
    "\n",
    "# Write data frame to file\n",
    "# Exposure/depths links depths to properties\n",
    "EXP_OUT_DIR = join(fp, 'exposure')\n",
    "Path(EXP_OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "DEPTHS_OUT_FILEP = join(EXP_OUT_DIR, 'depths.pqt')\n",
    "# fd_id is index, so set index=True\n",
    "depths.to_parquet(DEPTHS_OUT_FILEP,\n",
    "                  index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40920f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T17:18:14.237090Z",
     "start_time": "2023-02-05T17:18:13.531318Z"
    }
   },
   "source": [
    "## Subset to residential structures and write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16d958cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T20:09:24.255096Z",
     "start_time": "2023-03-14T20:09:13.068019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get residential structures\n",
    "nsi_res = nsi_gdf.loc[nsi_gdf['st_damcat'] == 'RES']\n",
    "\n",
    "# TODO: Need to update occtype variable to OPEN or ENC\n",
    "# when pile or pier found_type exists, but not\n",
    "# relevant for this first case study so avoiding the code\n",
    "\n",
    "# Write out to processed/exposure/\n",
    "EXP_OUT_FILEP = join(EXP_OUT_DIR, 'nsi_res.gpkg')\n",
    "nsi_res.to_file(EXP_OUT_FILEP, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4cda8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T17:01:13.595886Z",
     "start_time": "2023-02-06T17:01:13.146084Z"
    }
   },
   "source": [
    "# Process depth damage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c010ecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T17:07:00.593165Z",
     "start_time": "2023-02-06T17:07:00.065186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filepath to NACCS depth damage functions\n",
    "vul_dir = join(fr, 'vulnerability')\n",
    "# Read ddfs\n",
    "naccs = pd.read_csv(join(vul_dir, 'naccs_ddfs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4afe6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T17:31:49.308619Z",
     "start_time": "2023-02-06T17:31:49.244649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Need to write file in tidy format\n",
    "\n",
    "# Drop Description and Source columns\n",
    "# Melt on occupancy damage category\n",
    "# Each depth is associated with a percent damage\n",
    "dropcols = ['Description', 'Source']\n",
    "idvars = ['Occupancy', 'DamageCategory']\n",
    "naccs_melt = naccs.drop(columns=dropcols).melt(id_vars=idvars,\n",
    "                                               var_name='depth_str',\n",
    "                                               value_name='pctdam')\n",
    "\n",
    "# Need to convert depth_ft into a number\n",
    "# Replace ft with empty character\n",
    "# If string ends with m, make negative number\n",
    "# Else, make positive number\n",
    "naccs_melt['depth_str'] = naccs_melt['depth_str'].str.replace('ft', '')\n",
    "negdepth = naccs_melt.loc[naccs_melt['depth_str'].str[-1] == \n",
    "                          'm']['depth_str'].str[:-1].astype(float)*-1\n",
    "posdepth = naccs_melt.loc[naccs_melt['depth_str'].str[-1] != \n",
    "                          'm']['depth_str'].astype(float)\n",
    "\n",
    "naccs_melt.loc[naccs_melt['depth_str'].str[-1] == 'm',\n",
    "               'depth_ft'] = negdepth\n",
    "naccs_melt.loc[naccs_melt['depth_str'].str[-1] != 'm',\n",
    "               'depth_ft'] = posdepth\n",
    "\n",
    "# Divide pctdam by 100\n",
    "naccs_melt['reldam'] = naccs_melt['pctdam']/100\n",
    "\n",
    "# Delete depth_str and pctdam and standardize\n",
    "# column names\n",
    "dropcols = ['depth_str', 'pctdam']\n",
    "newcols = ['occtype', 'damcat', 'depth_ft', 'reldam']\n",
    "naccs_melt = naccs_melt.drop(columns=dropcols)\n",
    "naccs_melt.columns = newcols\n",
    "\n",
    "# Write out to processed/vulnerability/\n",
    "vuln_out_dir = join(fp, 'vulnerability')\n",
    "Path(vuln_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "vuln_out_filep = join(vuln_out_dir, 'naccs_ddfs.csv')\n",
    "naccs_melt.to_csv(vuln_out_filep, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icom_risk",
   "language": "python",
   "name": "icom_risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

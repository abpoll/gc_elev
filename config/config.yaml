# In the future, it makes sense to generate the county & state
# config from a pre-config script that takes in user input
# for which counties or areas they want to study. Then, 
# the config.yaml is generated from this user input
# in the following structure so that snakemake can do its
# magic. We would want to distribute jobs by 
# nation, state, county so they could run in parallel
FIPS: ["34007"]
STATEFIPS: ["34"]
STATEABBR: ["NJ"]
NATION: ["US"]

# Below are urls and api endpoints
# for obtaining all raw data
# We will organize by county, state
# and national downloads
# And then, within each, we will
# organize by url and api calls
# Finally, we will include key/val pairs
# for component type (i.e. haz, exp, vuln)
# and other identifiers (i.e. social, physical)
# that are useful for organizational logic

# There are different rules for downloading
# data from API or URL endpoints, since the former
# require some parameters whereas the latter
# point straight to a file to download
# We will first have keys
# for api/url 
# Then we will structure by keys
# for the data type (i.e. haz/exp)
# that will define file directories and paths
# These all need to be nested within 
# the following keys
# county, state, national, external
# we want to download data from
# largest to smallest scale (i.e. national, state, county)
# because of their set-type relationships (i.e. many counties in one state
# and many states in one nation)
# Some data downloads are not scale based, so
# downloaded once and from the "external" key
# (this is theoretical, not relevant to our case study)
download:
  FIPS:
    api:
      exp: 
        # NSI has an API endpoint
        # We call it county by county
        nsi: "https://nsi.sec.usace.army.mil/nsiapi/structures?fips={FIPS}"
      ref:
            # We use the Gloucester City, NJ municipal boundary as our clip
            # file for this case study
        clip: "https://services3.arcgis.com/JGF6qCAQFbROcocK/arcgis/rest/services/CamdenCountyMunicipalLayer/FeatureServer/0/query?f=geojson&where=(NAMELSAD%20IN%20(%27Gloucester%20City%20city%27))&outFields=*"
    url:
        # We use the national flood hazard layer for flood zones
        # These URLs currently are not in a structured format, as far as I know
        # and to generalize this may be better suited to a more dynamic
        # speficiation (i.e. maybe with url prefix and then the {fname}.zip specified
        # more dynamically)
        pol:
          nfhl: "https://hazards.fema.gov/nfhlv2/output/County/34007C_20160816.zip"
  STATEABBR:
    url:
      vuln:
        social:
          # replace STATE_ABBR with state abbreviation in the download rule
          # We have a helper function in a util/ directory that replaces
          # STATE with the STATE key at the top of this config.yml file
          # This is the NOAA SOVI data
          noaa: "https://coast.noaa.gov/htdata/SocioEconomic/SoVI2010/SoVI_2010_{STATEABBR}.zip"
      ref:
        # replace STATE_FIPS with st_fips in the download rule
        # We have a helper function in a util/ directory that replaces
        # Tract, block group, and block geospatial boundaries are available at state level
        tract: "https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_{STATEFIPS}_tract.zip"
        bg: "https://www2.census.gov/geo/tiger/TIGER2022/BG/tl_2022_{STATEFIPS}_bg.zip"
        block: "https://www2.census.gov/geo/tiger/TIGER2022/TABBLOCK20/tl_2022_{STATEFIPS}_tabblock20.zip"
  NATION:
    url:
      vuln:
        social:
          # CEJST and low moderate income designations available for the whole country
          cejst: "https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-communities.csv"
          lmi: "https://www.hudexchange.info/sites/onecpd/assets/File/ACS_2015_lowmod_blockgroup_all.xlsx"
      ref:
        # County and zip code tabulation area spatial data available for the whole country
        county: "https://www2.census.gov/geo/tiger/TIGER2022/COUNTY/tl_2022_us_county.zip"
        zcta: "https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip"
# We need to keep track of the format different api data is returned in
# to write it out
api_ext:
  nsi: ".json"
  clip: ".json"

# We need to keep track of which wildcards are used in urls
url_wildcards: ["{FIPS}", "{STATEABBR}", "{STATEFIPS}", "{NATION}"]

# We need to keep track of the hazard directory name
haz_dir_mid: "Combination_Rain_WL_Mid"
haz_dir_low: "Combination_Rain_WL_Lower"
haz_dir_high: "Combination_Rain_WL_Upper"
haz_dir_sub: "Combination_Rain_WL"

# Keep track of NSI CRS
nsi_crs: "EPSG:4326"

# Keep track of clip CRS
# The metadata says 26918, but when you
# use that and plot, you clearly see the
# coordinates are in degrees
# Upon further inspection, epsg 4326 appers
# to be the correct CRS
clip_crs: "EPSG:4326"

# Hazard model configurations
# Keep track of return periods
RPs: ["001", "002", "005", "010", "015", "020", "025", "050", "075", "100", "200", "500"]
haz_filename: "Max_WD_Comb_{RP}.asc"
haz_crs: "EPSG:26918"